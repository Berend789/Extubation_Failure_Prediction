{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "3b7e431a861a72513f361682db481bb043ab213b57189a56d42fe6b32fa57c58"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\berend\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\nC:\\Users\\berend\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\nC:\\Users\\berend\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\nC:\\Users\\berend\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from all_stand_var import conv_dict, vent_cols3\n",
    "from all_own_funct import memory_downscale,memory_upscale,evaluate,lin_reg_coef\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "from seaborn import heatmap\n",
    "from sklearn.metrics import roc_curve, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from scipy.stats import kurtosis\n",
    "from sklearn.metrics import roc_curve, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import locale\n",
    "import pickle\n",
    "locale.setlocale(locale.LC_ALL, 'fr_FR')\n",
    "output_folder = os.path.join(os.getcwd(), 'Results_LR_RF_v2','Static_redo')\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vent_cols3 = ['pat_hosp_id', 'pat_bd', 'pat_datetime', 'AdmissionDate','DischargeDate', 'mon_rr', 'mon_hr', 'mon_sat',\n",
    "              'mon_etco2', 'vent_m_fio2', 'vent_m_ppeak','vent_m_peep',\n",
    "             'mon_ibp_mean','pat_weight_act','vent_m_rr', 'vent_m_tv_exp']\n",
    "dtype_dict={'vent_cat': 'category','vent_machine':'category','vent_mode':'category'}\n",
    "df_raw=pd.read_csv(r'data\\sorted_bron_date.csv',delimiter=';',converters=conv_dict,usecols=vent_cols3,dtype=dtype_dict,parse_dates=['pat_bd','pat_datetime','AdmissionDate', 'DischargeDate'],na_values=['NULL','null', 'Null','nUll','nuLl','nulL'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "394\n",
      "c:\\Users\\berend\\Documents\\Python_Scripts\\Patient_Selection\\LR_build.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['pat_datetime_temp'] = pd.to_datetime(df['pat_datetime']).dt.date\n",
      "c:\\Users\\berend\\Documents\\Python_Scripts\\Patient_Selection\\LR_build.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['pat_bd'] = pd.to_datetime(df['pat_bd']).dt.date\n",
      "c:\\Users\\berend\\Documents\\Python_Scripts\\Patient_Selection\\LR_build.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['pat_bd']).dt.days.divide(365)\n",
      "count    3.409311e+06\n",
      "mean     3.840034e-01\n",
      "std      6.091721e-01\n",
      "min      0.000000e+00\n",
      "25%      9.315068e-02\n",
      "50%      1.479452e-01\n",
      "75%      3.753425e-01\n",
      "max      5.117808e+00\n",
      "Name: Age, dtype: float64\n",
      "38\n",
      "327\n",
      "mergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmerg\n",
      "38\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 3409311 entries, (5379, Timestamp('2012-11-27 19:00:00'), Timestamp('2012-12-07 10:15:00')) to (9986307, Timestamp('2014-01-09 11:30:00'), Timestamp('2014-01-17 14:20:00'))\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Dtype         \n",
      "---  ------           -----         \n",
      " 0   pat_datetime     datetime64[ns]\n",
      " 1   pat_weight_act   float32       \n",
      " 2   mon_etco2        float32       \n",
      " 3   mon_hr           float32       \n",
      " 4   mon_ibp_mean     float32       \n",
      " 5   mon_rr           float32       \n",
      " 6   mon_sat          float32       \n",
      " 7   vent_m_fio2      float32       \n",
      " 8   vent_m_peep      float32       \n",
      " 9   vent_m_ppeak     float32       \n",
      " 10  vent_m_rr        float32       \n",
      " 11  vent_m_tv_exp    float32       \n",
      " 12  Adnum            int64         \n",
      " 13  Age              float32       \n",
      " 14  Reintub          int64         \n",
      " 15  Extubation_date  datetime64[ns]\n",
      "dtypes: datetime64[ns](2), float32(12), int64(2)\n",
      "memory usage: 279.6 MB\n",
      "None\n",
      "326\n",
      "Trim\n",
      "37\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 230072 entries, (88, 2481139, Timestamp('2008-11-03 14:00:00'), Timestamp('2008-11-22 15:28:00')) to (206, 6611048, Timestamp('2019-12-23 20:35:00'), Timestamp('2020-01-07 11:30:00'))\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count   Dtype         \n",
      "---  ------           --------------   -----         \n",
      " 0   pat_datetime     230072 non-null  datetime64[ns]\n",
      " 1   pat_weight_act   230072 non-null  float32       \n",
      " 2   mon_etco2        168135 non-null  float32       \n",
      " 3   mon_hr           228495 non-null  float32       \n",
      " 4   mon_ibp_mean     102556 non-null  float32       \n",
      " 5   mon_rr           223194 non-null  float32       \n",
      " 6   mon_sat          226919 non-null  float32       \n",
      " 7   vent_m_fio2      225617 non-null  float32       \n",
      " 8   vent_m_peep      223351 non-null  float32       \n",
      " 9   vent_m_ppeak     229217 non-null  float32       \n",
      " 10  vent_m_rr        229999 non-null  float32       \n",
      " 11  vent_m_tv_exp    226006 non-null  float32       \n",
      " 12  Adnum            230072 non-null  int64         \n",
      " 13  Age              230072 non-null  float32       \n",
      " 14  Reintub          230072 non-null  int64         \n",
      " 15  Extubation_date  230072 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](2), float32(12), int64(2)\n",
      "memory usage: 19.3 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import LR_build as pp\n",
    "importlib.reload(pp)\n",
    "df = pp.data_pp_function(df_raw,path=output_folder,timestep='12H')\n",
    "#df=df.groupby('Admissionnumber',sort=False).fillna(method='ffill').fillna(method='bfill')\n",
    "#f = open(os.path.join('./Results_LR_RF_v2/', 'processed_df.txt'), 'rb')\n",
    "#df = pickle.load(f)\n",
    "#f.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "pat_datetime            0\npat_weight_act          0\nmon_etco2           61937\nmon_hr               1577\nmon_ibp_mean       127516\nmon_rr               6878\nmon_sat              3153\nvent_m_fio2          4455\nvent_m_peep          6721\nvent_m_ppeak          855\nvent_m_rr              73\nvent_m_tv_exp        4066\nAdnum                   0\nAge                     0\nReintub                 0\nExtubation_date         0\ndtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 230072 entries, 0 to 230071\n",
      "Data columns (total 20 columns):\n",
      " #   Column           Non-Null Count   Dtype         \n",
      "---  ------           --------------   -----         \n",
      " 0   level_0          230072 non-null  int64         \n",
      " 1   pat_hosp_id      230072 non-null  int64         \n",
      " 2   AdmissionDate    230072 non-null  datetime64[ns]\n",
      " 3   DischargeDate    230072 non-null  datetime64[ns]\n",
      " 4   pat_datetime     230072 non-null  datetime64[ns]\n",
      " 5   pat_weight_act   230072 non-null  float32       \n",
      " 6   mon_etco2        168135 non-null  float32       \n",
      " 7   mon_hr           228495 non-null  float32       \n",
      " 8   mon_ibp_mean     102556 non-null  float32       \n",
      " 9   mon_rr           223194 non-null  float32       \n",
      " 10  mon_sat          226919 non-null  float32       \n",
      " 11  vent_m_fio2      225617 non-null  float32       \n",
      " 12  vent_m_peep      223351 non-null  float32       \n",
      " 13  vent_m_ppeak     229217 non-null  float32       \n",
      " 14  vent_m_rr        229999 non-null  float32       \n",
      " 15  vent_m_tv_exp    226006 non-null  float32       \n",
      " 16  Adnum            230072 non-null  int64         \n",
      " 17  Age              230072 non-null  float32       \n",
      " 18  Reintub          230072 non-null  int64         \n",
      " 19  Extubation_date  230072 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](4), float32(12), int64(4)\n",
      "memory usage: 24.6 MB\n",
      "0      720\n",
      "208    720\n",
      "84     720\n",
      "339    720\n",
      "338    720\n",
      "      ... \n",
      "306    240\n",
      "47      65\n",
      "76      28\n",
      "284     10\n",
      "383      1\n",
      "Name: Adnum, Length: 327, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "df=df.reset_index(drop=False)\n",
    "df.info()\n",
    "def index_1hr(group):\n",
    "    group['mis']=(group['pat_datetime'].max()-group['pat_datetime'].min()).total_seconds()/60\n",
    "    return group\n",
    "#grouped = pd.Grouper(key='pat_datetime', freq='60min',label='left',convention='start')\n",
    "#df['idx_1hr']=df.groupby(['Adnum','pat_hosp_id','AdmissionDate','DischargeDate'],sort=False,as_index=False).ngroup().add(1)\n",
    "df=df.groupby('Adnum',sort=False,as_index=False).apply(index_1hr)\n",
    "print((df['Adnum'].value_counts()))\n",
    "df[['mis']]=StandardScaler().fit_transform(df[['mis']])\n",
    "df=df.set_index(['pat_hosp_id','AdmissionDate','DischargeDate'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 327 entries, 104 to 246\nData columns (total 4 columns):\n #   Column               Non-Null Count  Dtype  \n---  ------               --------------  -----  \n 0   pat_weight_act_mean  327 non-null    float32\n 1   Age_mean             327 non-null    float32\n 2   mis_mean             327 non-null    float64\n 3   Reintub_mean         327 non-null    int64  \ndtypes: float32(2), float64(1), int64(1)\nmemory usage: 10.2 KB\nNone\n"
     ]
    }
   ],
   "source": [
    "def x_modelling(df):\n",
    "    df=df[['pat_weight_act','Age','Adnum','mis','Reintub']]\n",
    "    #df=df.drop(['Extubation_date','level_0','pat_datetime', 'Reintub'],axis=1)\n",
    "    df=df.groupby(['Adnum'],sort=False).agg(['mean'])\n",
    "    df.columns = [\"_\".join(a) for a in df.columns.to_flat_index()]\n",
    "    df=df.reset_index().drop_duplicates().set_index('Adnum')\n",
    "    df=df.fillna(method='ffill').fillna(method='bfill')\n",
    "    return df\n",
    "x_f=x_modelling(df)\n",
    "\n",
    "print(x_f.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 327 entries, 104 to 246\nData columns (total 4 columns):\n #   Column               Non-Null Count  Dtype  \n---  ------               --------------  -----  \n 0   pat_weight_act_mean  327 non-null    float32\n 1   Age_mean             327 non-null    float32\n 2   mis_mean             327 non-null    float64\n 3   Reintub_mean         327 non-null    int64  \ndtypes: float32(2), float64(1), int64(1)\nmemory usage: 10.2 KB\nNone\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 36 entries, 203 to 384\nData columns (total 4 columns):\n #   Column               Non-Null Count  Dtype  \n---  ------               --------------  -----  \n 0   pat_weight_act_mean  36 non-null     float32\n 1   Age_mean             36 non-null     float32\n 2   mis_mean             36 non-null     float64\n 3   Reintub_mean         36 non-null     int64  \ndtypes: float32(2), float64(1), int64(1)\nmemory usage: 1.1 KB\nNone\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 291 entries, 104 to 246\nData columns (total 4 columns):\n #   Column               Non-Null Count  Dtype  \n---  ------               --------------  -----  \n 0   pat_weight_act_mean  291 non-null    float32\n 1   Age_mean             291 non-null    float32\n 2   mis_mean             291 non-null    float64\n 3   Reintub_mean         291 non-null    int64  \ndtypes: float32(2), float64(1), int64(1)\nmemory usage: 9.1 KB\nNone\n"
     ]
    }
   ],
   "source": [
    "x_1=x_f[x_f['Reintub_mean']==1]\n",
    "x_0=x_f[x_f['Reintub_mean']==0]\n",
    "print(x_f.info())\n",
    "print(x_1.info())\n",
    "print(x_0.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "count    327.000000\nmean       0.312404\nstd        0.514196\nmin        0.007553\n25%        0.095455\n50%        0.150472\n75%        0.303777\nmax        5.117009\nName: Age_mean, dtype: float64\ncount    291.000000\nmean       0.304458\nstd        0.517987\nmin        0.007553\n25%        0.097260\n50%        0.150529\n75%        0.302407\nmax        5.117009\nName: Age_mean, dtype: float64\nlol\ncount    36.000000\nmean      0.376634\nstd       0.484515\nmin       0.024658\n25%       0.088593\n50%       0.145329\n75%       0.489378\nmax       2.185696\nName: Age_mean, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(x_f['Age_mean'].describe())\n",
    "print(x_0['Age_mean'].describe())\n",
    "print('lol')\n",
    "print(x_1['Age_mean'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pat=pd.read_excel(r'Results\\admissiondate_v2.xlsx', parse_dates=[\n",
    "                            'AdmissionDate', 'DischargeDate'])\n",
    "group=pat.groupby('pat_hosp_id',sort=False).max().reset_index()\n",
    "group.drop_duplicates('pat_hosp_id',inplace=True)\n",
    "df_train,df_val,df_test=pp.split_stratified_into_train_val_test(group, stratify_colname='Reintub',\n",
    "                                         frac_train=0.60, frac_val=0.1, frac_test=0.3,\n",
    "                                         random_state=1)\n",
    "print(df_train.info())\n",
    "\n",
    "train_pat=df_train['pat_hosp_id'].unique()\n",
    "test_pat=df_test['pat_hosp_id'].unique()\n",
    "val_pat=df_val['pat_hosp_id'].unique()\n",
    "\n",
    "df_train = df[df.index.get_level_values('pat_hosp_id').isin(train_pat)]\n",
    "df_val = df[df.index.get_level_values('pat_hosp_id').isin(val_pat)]\n",
    "df_test = df[df.index.get_level_values('pat_hosp_id').isin(test_pat)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def y_modelling(df):\n",
    "    y=df[['Reintub','Adnum']]\n",
    "    y=y.groupby(['Adnum'],sort=False).agg(['max'])\n",
    "    y.columns = [\"_\".join(a) for a in y.columns.to_flat_index()]\n",
    "    y=y.reset_index().drop_duplicates().set_index('Adnum')\n",
    "    y=y[~y.index.duplicated(keep='last')]\n",
    "    y=y.fillna(method='ffill').fillna(method='bfill')\n",
    "    return y\n",
    "Y_TRAIN=y_modelling(df_train)\n",
    "Y_TEST=y_modelling(df_test)\n",
    "Y_VAL=y_modelling(df_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_TRAIN.value_counts())\n",
    "print(Y_VAL.value_counts())\n",
    "print(Y_TEST.value_counts())\n",
    "Y_TRAIN=Y_TRAIN['Reintub_max'].to_numpy()\n",
    "Y_TEST=Y_TEST['Reintub_max'].to_numpy()\n",
    "Y_VAL=Y_VAL['Reintub_max'].to_numpy()\n",
    "Y_TRAIN=np.append(Y_TRAIN,Y_VAL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_modelling(df):\n",
    "    df=df[['pat_weight_act','Age','Adnum','mis']]\n",
    "    #df=df.drop(['Extubation_date','level_0','pat_datetime', 'Reintub'],axis=1)\n",
    "    df=df.groupby(['Adnum'],sort=False).agg(['mean'])\n",
    "    df.columns = [\"_\".join(a) for a in df.columns.to_flat_index()]\n",
    "    df=df.reset_index().drop_duplicates().set_index('Adnum')\n",
    "    df=df.fillna(method='ffill').fillna(method='bfill')\n",
    "    return df\n",
    "X_TRAIN=x_modelling(df_train)\n",
    "X_TEST=x_modelling(df_test)\n",
    "X_VAL=x_modelling(df_val)\n",
    "print(X_TRAIN.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TRAIN=X_TRAIN.append(X_VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(os.path.join(output_folder, 'x_train.txt'), 'wb')\n",
    "pickle.dump(X_TRAIN, f)\n",
    "f.close()\n",
    "\n",
    "f = open(os.path.join(output_folder, 'x_test.txt'), 'wb')\n",
    "pickle.dump(X_TEST, f)\n",
    "f.close()\n",
    "\n",
    "f = open(os.path.join(output_folder, 'y_train.txt'), 'wb')\n",
    "pickle.dump(Y_TRAIN, f)\n",
    "f.close()\n",
    "\n",
    "f = open(os.path.join(output_folder, 'y_test.txt'), 'wb')\n",
    "pickle.dump(Y_TEST, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 50, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [1,2,3,4, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 30, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_TRAIN, Y_TRAIN)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix,average_precision_score,f1_score,roc_curve,roc_auc_score,plot_confusion_matrix\n",
    "\n",
    "base_model = RandomForestClassifier(n_estimators = 10, random_state = 42,max_depth=10)\n",
    "base_model.fit(X_TRAIN, Y_TRAIN)\n",
    "base_accuracy = evaluate(base_model, X_TEST, Y_TEST,'base RF',output_folder)\n",
    "\n",
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy = evaluate(best_random, X_TEST,Y_TEST,'Best random RF',output_folder)\n",
    "\n",
    "if base_accuracy > random_accuracy:\n",
    "    best_random = base_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix,average_precision_score,f1_score,roc_curve,roc_auc_score,plot_confusion_matrix\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "from all_own_funct import roc_auc_ci\n",
    "try:\n",
    "    pdf = PdfPages(os.path.join(output_folder,f\"Figures_all_t.pdf\"))\n",
    "except PermissionError:\n",
    "    os.remove(os.path.join(output_folder,f\"Figures_all.pdf\"))\n",
    "    os.remove(os.path.join(output_folder,f\"Result_scores_all.txt\"))\n",
    "clf = best_random \n",
    "\n",
    "y_pred_clas=clf.predict(X_TEST)\n",
    "# Predict the probabilities, function depends on used classifier\n",
    "\n",
    "try:\n",
    "    y_pred_prob=clf.predict_proba(X_TEST)\n",
    "    y_pred_prob=y_pred_prob[:,1]\n",
    "except:\n",
    "    try:\n",
    "        y_pred_prob=clf.decision_function(X_TEST)\n",
    "    except:\n",
    "        y_pred_prob=y_pred_clas\n",
    "\n",
    "report=classification_report(Y_TEST,y_pred_clas,target_names=['No Reintubation','Reintubation'])\n",
    "score=clf.score(X_TEST,Y_TEST)\n",
    "average_precision = average_precision_score(Y_TEST, y_pred_prob)\n",
    "f1_s=f1_score(Y_TEST, y_pred_clas)\n",
    "\n",
    "# write scoring metrics to file\n",
    "with open(os.path.join(output_folder,f\"Result_scores_all.txt\"),'a') as file:\n",
    "    file.write(f\"Results for RF on training set\\n\\n\")\n",
    "    file.write(f\"Classification report \\n {report} \\n\")\n",
    "    file.write(f\"Hold_out_scores {score} \\n\")\n",
    "    file.write(f\"Average precision score {average_precision} \\n\")\n",
    "    file.write(f\"F1 score {f1_s} \\n\\n\\n\")\n",
    "\n",
    "plot_confusion_matrix(clf,X_TEST,Y_TEST)\n",
    "plt.title(f\"Confusion matrix of random forrest\")\n",
    "fig=plt.gcf()\n",
    "pdf.savefig(fig)\n",
    "plt.close(fig)\n",
    "\n",
    "fpr, tpr, _ = roc_curve(Y_TEST,  y_pred_prob)\n",
    "auc = roc_auc_score(Y_TEST, y_pred_prob)\n",
    "\n",
    "n_bootstraps = 2000\n",
    "rng_seed = 42  # control reproducibility\n",
    "bootstrapped_scores = []\n",
    "\n",
    "rng = np.random.RandomState(rng_seed)\n",
    "for i in range(n_bootstraps):\n",
    "    # bootstrap by sampling with replacement on the prediction indices\n",
    "    indices = rng.randint(0, len(y_pred_prob), len(y_pred_prob))\n",
    "    if len(np.unique(Y_TEST[indices])) < 2:\n",
    "        # We need at least one positive and one negative sample for ROC AUC\n",
    "        # to be defined: reject the sample\n",
    "        continue\n",
    "\n",
    "    score = roc_auc_score(Y_TEST[indices], y_pred_prob[indices])\n",
    "    bootstrapped_scores.append(score)\n",
    "    #print(\"Bootstrap #{} ROC area: {:0.3f}\".format(i + 1, score))\n",
    "\n",
    "sorted_scores = np.array(bootstrapped_scores)\n",
    "sorted_scores.sort()\n",
    "\n",
    "# Computing the lower and upper bound of the 90% confidence interval\n",
    "# You can change the bounds percentiles to 0.025 and 0.975 to get\n",
    "# a 95% confidence interval instead.\n",
    "confidence_lower = sorted_scores[int(0.05 * len(sorted_scores))]\n",
    "confidence_upper = sorted_scores[int(0.95 * len(sorted_scores))]\n",
    "with open(os.path.join(output_folder,f\"Result_scores_all.txt\"),'a') as file:\n",
    "    file.write(\"\\nConfidence interval for the score: [{:0.3f} - {:0.3}]\\n\".format(\n",
    "    confidence_lower, confidence_upper))\n",
    "a=roc_auc_ci(Y_TEST,y_pred_prob)\n",
    "print(a)\n",
    "\n",
    "\n",
    "plt.plot(fpr,tpr,label=f\"auc={auc}\",linewidth=1.5,markersize=1)\n",
    "\n",
    "plt.legend(loc=4,fontsize='xx-small')\n",
    "plt.title(f'ROC of Random Forrest hour data')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([0,1])\n",
    "axes.set_ylim([0,1])\n",
    "fig=plt.gcf()\n",
    "pdf.savefig(fig)\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "# Number of features to consider at every split\n",
    "solver =['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "# Maximum number of levels in tree\n",
    "class_weight=[{0:0.1,1:0.9},'balanced',None]\n",
    "# Minimum number of samples required to split a node\n",
    "penalty=['l1', 'l2', 'elasticnet', None]\n",
    "# Minimum number of samples required at each leaf node\n",
    "C=np.logspace(-3,3,7)\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'solver':solver,\n",
    "                'class_weight':class_weight,\n",
    "                'penalty':penalty,\n",
    "                'C':C,\n",
    "                'penalty':penalty}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create the base model to tune\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "lr_random = RandomizedSearchCV(estimator = lr , param_distributions = random_grid, n_iter = 20, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "lr_random.fit(X_TRAIN, Y_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_lr = LogisticRegression(max_iter=1000)\n",
    "base_model_lr.fit(X_TRAIN, Y_TRAIN)\n",
    "base_accuracy_lr = evaluate(base_model, X_TEST, Y_TEST,'base LR',output_folder)\n",
    "\n",
    "best_random_lr = lr_random.best_estimator_\n",
    "random_accuracy_lr = evaluate(best_random, X_TEST,Y_TEST,'Best Random LR',output_folder)\n",
    "if base_accuracy_lr > random_accuracy_lr:\n",
    "    best_random_lr = base_model_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = best_random_lr\n",
    "\n",
    "y_pred_clas=clf.predict(X_TEST)\n",
    "# Predict the probabilities, function depends on used classifier\n",
    "\n",
    "try:\n",
    "    y_pred_prob=clf.predict_proba(X_TEST)\n",
    "    y_pred_prob=y_pred_prob[:,1]\n",
    "except:\n",
    "    try:\n",
    "        y_pred_prob=clf.decision_function(X_TEST)\n",
    "    except:\n",
    "        y_pred_prob=y_pred_clas\n",
    "\n",
    "report=classification_report(Y_TEST,y_pred_clas,target_names=['No Reintubation','Reintubation'])\n",
    "score=clf.score(X_TEST,Y_TEST)\n",
    "average_precision = average_precision_score(Y_TEST, y_pred_prob)\n",
    "f1_s=f1_score(Y_TEST, y_pred_clas)\n",
    "\n",
    "with open(os.path.join(output_folder,f\"Result_scores_all.txt\"),'a') as file:\n",
    "    file.write(f\"Results for LR on training\\n\\n\")\n",
    "    file.write(f\"Classification report \\n {report} \\n\")\n",
    "    file.write(f\"Hold_out_scores {score} \\n\")\n",
    "    file.write(f\"Average precision score {average_precision} \\n\")\n",
    "    file.write(f\"F1 score {f1_s} \\n\\n\\n\")\n",
    "\n",
    "plot_confusion_matrix(clf,X_TEST,Y_TEST)\n",
    "plt.title(f\"Confusion matrix of logistic regression\")\n",
    "fig=plt.gcf()\n",
    "pdf.savefig(fig)\n",
    "plt.close(fig)\n",
    "\n",
    "fpr, tpr, _ = roc_curve(Y_TEST,  y_pred_prob)\n",
    "auc = roc_auc_score(Y_TEST, y_pred_prob)\n",
    "print(auc)\n",
    "\n",
    "n_bootstraps = 2000\n",
    "rng_seed = 42  # control reproducibility\n",
    "bootstrapped_scores = []\n",
    "\n",
    "rng = np.random.RandomState(rng_seed)\n",
    "for i in range(n_bootstraps):\n",
    "    # bootstrap by sampling with replacement on the prediction indices\n",
    "    indices = rng.randint(0, len(y_pred_prob), len(y_pred_prob))\n",
    "    if len(np.unique(Y_TEST[indices])) < 2:\n",
    "        # We need at least one positive and one negative sample for ROC AUC\n",
    "        # to be defined: reject the sample\n",
    "        continue\n",
    "\n",
    "    score = roc_auc_score(Y_TEST[indices], y_pred_prob[indices])\n",
    "    bootstrapped_scores.append(score)\n",
    "    #print(\"Bootstrap #{} ROC area: {:0.3f}\".format(i + 1, score))\n",
    "\n",
    "sorted_scores = np.array(bootstrapped_scores)\n",
    "sorted_scores.sort()\n",
    "\n",
    "# Computing the lower and upper bound of the 90% confidence interval\n",
    "# You can change the bounds percentiles to 0.025 and 0.975 to get\n",
    "# a 95% confidence interval instead.\n",
    "confidence_lower = sorted_scores[int(0.05 * len(sorted_scores))]\n",
    "confidence_upper = sorted_scores[int(0.95 * len(sorted_scores))]\n",
    "with open(os.path.join(output_folder,f\"Result_scores_all.txt\"),'a') as file:\n",
    "    file.write(\"\\nConfidence interval for the score: [{:0.3f} - {:0.3}]\\n\".format(\n",
    "    confidence_lower, confidence_upper))\n",
    "\n",
    "a=roc_auc_ci(Y_TEST,y_pred_prob)\n",
    "print(a)\n",
    "\n",
    "plt.plot(fpr,tpr,label=f\"auc={auc}\",linewidth=1.5,markersize=1)\n",
    "\n",
    "\n",
    "plt.legend(loc=4,fontsize='xx-small')\n",
    "plt.title(f'ROC of Logistic Regression data')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([0,1])\n",
    "axes.set_ylim([0,1])\n",
    "fig=plt.gcf()\n",
    "pdf.savefig(fig)\n",
    "plt.close(fig)\n",
    "pdf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open(os.path.join(output_folder,'ran_for.sav'), 'wb')\n",
    "pickle.dump(best_random, f)\n",
    "f.close()\n",
    "\n",
    "f = open(os.path.join(output_folder,'log_reg.sav'), 'wb')\n",
    "pickle.dump(best_random_lr, f)\n",
    "f.close()"
   ]
  }
 ]
}