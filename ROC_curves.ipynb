{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "3b7e431a861a72513f361682db481bb043ab213b57189a56d42fe6b32fa57c58"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pylab as plt\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import sklearn.impute as skin\r\n",
    "from sqlalchemy import create_engine\r\n",
    "import locale\r\n",
    "import os\r\n",
    "from numpy import loadtxt\r\n",
    "import pickle\r\n",
    "\r\n",
    "\"\"\"\r\n",
    "File to create the different ROC plots as reported in the thesis\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "output_folder=os.path.join(os.getcwd(),'Result_ROC_curves')\r\n",
    "if not os.path.exists(output_folder):\r\n",
    "    os.makedirs(output_folder)\r\n",
    "\r\n",
    "locale.setlocale(locale.LC_ALL,'fr_FR')\r\n",
    "from sklearn.metrics import classification_report, confusion_matrix,average_precision_score,f1_score,roc_curve,roc_auc_score,plot_confusion_matrix\r\n",
    "\r\n",
    "\r\n",
    "# Load in the needed models and test sets per model\r\n",
    "output_folder = os.path.join(os.getcwd(), 'Results_LR_RF_CHD_v3','1u_Results')\r\n",
    "\r\n",
    "    \r\n",
    "f = open(os.path.join(output_folder,'ran_for.sav'), 'rb')\r\n",
    "best_rf=pickle.load(f)\r\n",
    "f.close()\r\n",
    "\r\n",
    "f = open(os.path.join(output_folder,'log_reg.sav'), 'rb')\r\n",
    "best_lr=pickle.load(f)\r\n",
    "f.close()\r\n",
    "\r\n",
    "f = open(os.path.join(output_folder,'x_test.txt'), 'rb')\r\n",
    "X_TEST=pickle.load(f)\r\n",
    "f.close()\r\n",
    "\r\n",
    "f = open(os.path.join(output_folder,'y_test.txt'), 'rb')\r\n",
    "Y_TEST=pickle.load(f)\r\n",
    "f.close()\r\n",
    "\r\n",
    "clf = best_rf\r\n",
    "clf_lr = best_lr\r\n",
    "\r\n",
    "y_pred_prob_rf=clf.predict_proba(X_TEST)[:,1]\r\n",
    "y_pred_prob_lr=clf_lr.predict_proba(X_TEST)[:,1]\r\n",
    "\r\n",
    "auc_rf = roc_auc_score(Y_TEST, y_pred_prob_rf)\r\n",
    "auc_lr = roc_auc_score(Y_TEST, y_pred_prob_lr)\r\n",
    "\r\n",
    "# take AUROC of best model\r\n",
    "if auc_rf > auc_lr:\r\n",
    "    y_pred_prob = y_pred_prob_rf\r\n",
    "    fpr_b_1u, tpr_b_1u, _ = roc_curve(Y_TEST,  y_pred_prob)\r\n",
    "    auc_b_1u = auc_rf\r\n",
    "    print('RF')\r\n",
    "else:\r\n",
    "    print('LR')\r\n",
    "    y_pred_prob = y_pred_prob_lr\r\n",
    "    fpr_b_1u, tpr_b_1u, _ = roc_curve(Y_TEST,  y_pred_prob)\r\n",
    "    auc_b_1u = auc_lr\r\n",
    "\r\n",
    "auc_b_1u=round(auc_b_1u,2)\r\n",
    "n_bootstraps = 2000\r\n",
    "rng_seed = 42  # control reproducibility\r\n",
    "bootstrapped_scores = []\r\n",
    "# Bootstrapping to calculate 95% CI \r\n",
    "rng = np.random.RandomState(rng_seed)\r\n",
    "for i in range(n_bootstraps):\r\n",
    "    # bootstrap by sampling with replacement on the prediction indices\r\n",
    "    indices = rng.randint(0, len(y_pred_prob), len(y_pred_prob))\r\n",
    "    if len(np.unique(Y_TEST[indices])) < 2:\r\n",
    "        # We need at least one positive and one negative sample for ROC AUC\r\n",
    "        # to be defined: reject the sample\r\n",
    "        continue\r\n",
    "\r\n",
    "    score = roc_auc_score(Y_TEST[indices], y_pred_prob[indices])\r\n",
    "    bootstrapped_scores.append(score)\r\n",
    "    #print(\"Bootstrap #{} ROC area: {:0.3f}\".format(i + 1, score))\r\n",
    "\r\n",
    "sorted_scores = np.array(bootstrapped_scores)\r\n",
    "sorted_scores.sort()\r\n",
    "\r\n",
    "# Computing the lower and upper bound of the 90% confidence interval\r\n",
    "# You can change the bounds percentiles to 0.025 and 0.975 to get\r\n",
    "# a 95% confidence interval instead.\r\n",
    "confidence_lower_b_1u = round(sorted_scores[int(0.05 * len(sorted_scores))],2)\r\n",
    "confidence_upper_b_1u = round(sorted_scores[int(0.95 * len(sorted_scores))],2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# The same as before, but now for another model\r\n",
    "output_folder = os.path.join(os.getcwd(), 'Results_LR_RF_CHD_v3','12u_result')\r\n",
    "    \r\n",
    "f = open(os.path.join(output_folder,'ran_for.sav'), 'rb')\r\n",
    "best_rf=pickle.load(f)\r\n",
    "f.close()\r\n",
    "f = open(os.path.join(output_folder,'log_reg.sav'), 'rb')\r\n",
    "best_lr=pickle.load(f)\r\n",
    "f.close()\r\n",
    "f = open(os.path.join(output_folder,'x_test.txt'), 'rb')\r\n",
    "X_TEST=pickle.load(f)\r\n",
    "f.close()\r\n",
    "f = open(os.path.join(output_folder,'y_test.txt'), 'rb')\r\n",
    "Y_TEST=pickle.load(f)\r\n",
    "f.close()\r\n",
    "\r\n",
    "\r\n",
    "clf = best_rf\r\n",
    "clf_lr = best_lr\r\n",
    "\r\n",
    "y_pred_prob_rf=clf.predict_proba(X_TEST)[:,1]\r\n",
    "y_pred_prob_lr=clf_lr.predict_proba(X_TEST)[:,1]\r\n",
    "\r\n",
    "auc_rf = roc_auc_score(Y_TEST, y_pred_prob_rf)\r\n",
    "auc_lr = roc_auc_score(Y_TEST, y_pred_prob_lr)\r\n",
    "\r\n",
    "if auc_rf > auc_lr:\r\n",
    "    y_pred_prob = y_pred_prob_rf\r\n",
    "    fpr_b_12u, tpr_b_12u, _ = roc_curve(Y_TEST,  y_pred_prob)\r\n",
    "    auc_b_12u = auc_rf\r\n",
    "    print('RF')\r\n",
    "else:\r\n",
    "    print('LR')\r\n",
    "    y_pred_prob = y_pred_prob_lr\r\n",
    "    fpr_b_12u, tpr_b_12u, _ = roc_curve(Y_TEST,  y_pred_prob)\r\n",
    "    auc_b_12u = auc_lr\r\n",
    "auc_b_12u=round(auc_b_12u,2)\r\n",
    "n_bootstraps = 2000\r\n",
    "rng_seed = 42  # control reproducibility\r\n",
    "bootstrapped_scores = []\r\n",
    "\r\n",
    "rng = np.random.RandomState(rng_seed)\r\n",
    "for i in range(n_bootstraps):\r\n",
    "    # bootstrap by sampling with replacement on the prediction indices\r\n",
    "    indices = rng.randint(0, len(y_pred_prob), len(y_pred_prob))\r\n",
    "    if len(np.unique(Y_TEST[indices])) < 2:\r\n",
    "        # We need at least one positive and one negative sample for ROC AUC\r\n",
    "        # to be defined: reject the sample\r\n",
    "        continue\r\n",
    "\r\n",
    "    score = roc_auc_score(Y_TEST[indices], y_pred_prob[indices])\r\n",
    "    bootstrapped_scores.append(score)\r\n",
    "    #print(\"Bootstrap #{} ROC area: {:0.3f}\".format(i + 1, score))\r\n",
    "\r\n",
    "sorted_scores = np.array(bootstrapped_scores)\r\n",
    "sorted_scores.sort()\r\n",
    "\r\n",
    "# Computing the lower and upper bound of the 90% confidence interval\r\n",
    "# You can change the bounds percentiles to 0.025 and 0.975 to get\r\n",
    "# a 95% confidence interval instead.\r\n",
    "confidence_lower_b_12u = round(sorted_scores[int(0.05 * len(sorted_scores))],2)\r\n",
    "confidence_upper_b_12u = round(sorted_scores[int(0.95 * len(sorted_scores))],2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "output_folder = os.path.join(os.getcwd(), 'Results_LR_RF_CHD_v3','Static')\r\n",
    "    \r\n",
    "f = open(os.path.join(output_folder,'ran_for.sav'), 'rb')\r\n",
    "best_rf=pickle.load(f)\r\n",
    "f.close()\r\n",
    "f = open(os.path.join(output_folder,'log_reg.sav'), 'rb')\r\n",
    "best_lr=pickle.load(f)\r\n",
    "f.close()\r\n",
    "f = open(os.path.join(output_folder,'x_test.txt'), 'rb')\r\n",
    "X_TEST=pickle.load(f)\r\n",
    "f.close()\r\n",
    "f = open(os.path.join(output_folder,'y_test.txt'), 'rb')\r\n",
    "Y_TEST=pickle.load(f)\r\n",
    "f.close()\r\n",
    "\r\n",
    "\r\n",
    "clf = best_rf\r\n",
    "clf_lr = best_lr\r\n",
    "\r\n",
    "y_pred_prob_rf=clf.predict_proba(X_TEST)[:,1]\r\n",
    "y_pred_prob_lr=clf_lr.predict_proba(X_TEST)[:,1]\r\n",
    "\r\n",
    "auc_rf = roc_auc_score(Y_TEST, y_pred_prob_rf)\r\n",
    "auc_lr = roc_auc_score(Y_TEST, y_pred_prob_lr)\r\n",
    "\r\n",
    "if auc_rf > auc_lr:\r\n",
    "    y_pred_prob = y_pred_prob_rf\r\n",
    "    fpr_b_stat, tpr_b_stat, _ = roc_curve(Y_TEST,  y_pred_prob)\r\n",
    "    auc_b_stat = auc_rf\r\n",
    "    print('RF')\r\n",
    "else:\r\n",
    "    print('LR')\r\n",
    "    y_pred_prob = y_pred_prob_lr\r\n",
    "    fpr_b_stat, tpr_b_stat, _ = roc_curve(Y_TEST,  y_pred_prob)\r\n",
    "    auc_b_stat = auc_lr\r\n",
    "    \r\n",
    "auc_b_stat=round(auc_b_stat,2)    \r\n",
    "n_bootstraps = 2000\r\n",
    "rng_seed = 42  # control reproducibility\r\n",
    "bootstrapped_scores = []\r\n",
    "\r\n",
    "rng = np.random.RandomState(rng_seed)\r\n",
    "for i in range(n_bootstraps):\r\n",
    "    # bootstrap by sampling with replacement on the prediction indices\r\n",
    "    indices = rng.randint(0, len(y_pred_prob), len(y_pred_prob))\r\n",
    "    if len(np.unique(Y_TEST[indices])) < 2:\r\n",
    "        # We need at least one positive and one negative sample for ROC AUC\r\n",
    "        # to be defined: reject the sample\r\n",
    "        continue\r\n",
    "\r\n",
    "    score = roc_auc_score(Y_TEST[indices], y_pred_prob[indices])\r\n",
    "    bootstrapped_scores.append(score)\r\n",
    "    #print(\"Bootstrap #{} ROC area: {:0.3f}\".format(i + 1, score))\r\n",
    "\r\n",
    "sorted_scores = np.array(bootstrapped_scores)\r\n",
    "sorted_scores.sort()\r\n",
    "\r\n",
    "# Computing the lower and upper bound of the 90% confidence interval\r\n",
    "# You can change the bounds percentiles to 0.025 and 0.975 to get\r\n",
    "# a 95% confidence interval instead.\r\n",
    "confidence_lower_b_stat = round(sorted_scores[int(0.05 * len(sorted_scores))],2)\r\n",
    "confidence_upper_b_stat = round(sorted_scores[int(0.95 * len(sorted_scores))],2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# AUROC for base RNN-LSTM\r\n",
    "from keras.models import Model, Input, load_model\r\n",
    "from RNN_LTSM_CHD import return_loaded_model\r\n",
    "\r\n",
    "output_folder = os.path.join(os.getcwd(), 'Results_RNN_CHD_v3', 'Base')\r\n",
    "\r\n",
    "target = 'Reintub'\r\n",
    "X_TEST = pickle.load(open(os.path.join(output_folder,'pickled_object_CHD','X_TEST_{0}.txt'.format(target)), 'rb'))\r\n",
    "Y_TEST = pickle.load(open(os.path.join(output_folder,'pickled_object_CHD','Y_TEST_{0}.txt'.format(target)), 'rb'))\r\n",
    "X_BOOLMAT_TEST = pickle.load(open(os.path.join(output_folder,'pickled_object_CHD','x_boolmat_test_{0}.txt'.format(target)), 'rb'))\r\n",
    "Y_BOOLMAT_TEST = pickle.load(open(os.path.join(output_folder,'pickled_object_CHD','y_boolmat_test_{0}.txt'.format(target)), 'rb'))\r\n",
    "\r\n",
    "m = return_loaded_model(model_name=\"ltsm_final_no_mask_Rein_pad14\",output_folder=output_folder)\r\n",
    "\r\n",
    "X_TEST_MASK = np.copy(X_TEST)\r\n",
    "X_TEST_MASK[X_BOOLMAT_TEST] = 0\r\n",
    "Y_PRED_mask_0 = m.predict(X_TEST_MASK)\r\n",
    "del X_TEST_MASK\r\n",
    "\r\n",
    "fpr_b_rn, tpr_b_rn, thresholds_100 = roc_curve(Y_TEST[~Y_BOOLMAT_TEST], Y_PRED_mask_0[~Y_BOOLMAT_TEST])\r\n",
    "auc_b_rn=roc_auc_score(Y_TEST[~Y_BOOLMAT_TEST], Y_PRED_mask_0[~Y_BOOLMAT_TEST])\r\n",
    "auc_b_rn=round(auc_b_rn,2)\r\n",
    "n_bootstraps = 2000\r\n",
    "rng_seed = 42  # control reproducibility\r\n",
    "bootstrapped_scores = []\r\n",
    "Y_TEST=Y_TEST[~Y_BOOLMAT_TEST]\r\n",
    "y_pred_prob=Y_PRED_mask_0[~Y_BOOLMAT_TEST]\r\n",
    "rng = np.random.RandomState(rng_seed)\r\n",
    "for i in range(n_bootstraps):\r\n",
    "    # bootstrap by sampling with replacement on the prediction indices\r\n",
    "    indices = rng.randint(0, len(y_pred_prob), len(y_pred_prob))\r\n",
    "    if len(np.unique(Y_TEST[indices])) < 2:\r\n",
    "        # We need at least one positive and one negative sample for ROC AUC\r\n",
    "        # to be defined: reject the sample\r\n",
    "        continue\r\n",
    "\r\n",
    "    score = roc_auc_score(Y_TEST[indices], y_pred_prob[indices])\r\n",
    "    bootstrapped_scores.append(score)\r\n",
    "    #print(\"Bootstrap #{} ROC area: {:0.3f}\".format(i + 1, score))\r\n",
    "\r\n",
    "sorted_scores = np.array(bootstrapped_scores)\r\n",
    "sorted_scores.sort()\r\n",
    "\r\n",
    "# Computing the lower and upper bound of the 90% confidence interval\r\n",
    "# You can change the bounds percentiles to 0.025 and 0.975 to get\r\n",
    "# a 95% confidence interval instead.\r\n",
    "confidence_lower_b_rn = round(sorted_scores[int(0.05 * len(sorted_scores))],2)\r\n",
    "confidence_upper_b_rn = round(sorted_scores[int(0.95 * len(sorted_scores))],2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create figure of different ROC's\r\n",
    "from matplotlib.backends.backend_pdf import PdfPages\r\n",
    "output_folder=os.path.join(os.getcwd(),'Result_ROC_curves')\r\n",
    "pdf_ROC = PdfPages(os.path.join(output_folder,f\"ROC of CHD.pdf\"))\r\n",
    "plt.plot(fpr_b_stat, tpr_b_stat,'k--',label=f\"RF, static features, AUC={auc_b_stat} [{confidence_lower_b_stat} - {confidence_upper_b_stat}]\",linewidth=.7,markersize=1)\r\n",
    "plt.plot(fpr_b_1u, tpr_b_1u,'b-',label=f\"LR, per hour features, AUC={auc_b_1u} [{confidence_lower_b_1u} - {confidence_upper_b_1u}]\",linewidth=.7,markersize=1)\r\n",
    "plt.plot(fpr_b_12u, tpr_b_12u,'r*-',label=f\"RF, 12 hour features, AUC={auc_b_12u} [{confidence_lower_b_12u} - {confidence_upper_b_12u}]\",linewidth=.7,markersize=1)\r\n",
    "plt.plot(fpr_b_rn, tpr_b_rn,'m-',label=f\"Base RNN-LSTM, AUC={auc_b_rn} [{confidence_lower_b_rn} - {confidence_upper_b_rn}]\",linewidth=.7,markersize=1)\r\n",
    "\r\n",
    "\r\n",
    "plt.legend(loc=4,fontsize='xx-small')\r\n",
    "plt.title(f'ROC of CHD cohort, control results')\r\n",
    "plt.xlabel('False Positive Rate')\r\n",
    "plt.ylabel('True Positive Rate')\r\n",
    "axes = plt.gca()\r\n",
    "axes.set_xlim([0,1])\r\n",
    "axes.set_ylim([0,1])\r\n",
    "fig=plt.gcf()\r\n",
    "pdf_ROC.savefig(fig)\r\n",
    "plt.show(fig)\r\n",
    "plt.close(fig)\r\n",
    "pdf_ROC.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load in base model\r\n",
    "from keras.models import Model, Input, load_model\r\n",
    "from RNN_LTSM_CHD import return_loaded_model\r\n",
    "import keras\r\n",
    "from sklearn.metrics import brier_score_loss\r\n",
    "import sklearn.metrics as metrics\r\n",
    "from sklearn.metrics import classification_report, confusion_matrix,average_precision_score,f1_score,roc_curve,roc_auc_score,plot_confusion_matrix\r\n",
    "from matplotlib.backends.backend_pdf import PdfPages\r\n",
    "output_folder = os.path.join(os.getcwd(), 'Results_RNN_CHD_v3', 'Base')\r\n",
    "\r\n",
    "target = 'Reintub'\r\n",
    "X_TEST = pickle.load(open(os.path.join(output_folder,'pickled_object_CHD','X_TEST_{0}.txt'.format(target)), 'rb'))\r\n",
    "Y_TEST = pickle.load(open(os.path.join(output_folder,'pickled_object_CHD','Y_TEST_{0}.txt'.format(target)), 'rb'))\r\n",
    "X_BOOLMAT_TEST = pickle.load(open(os.path.join(output_folder,'pickled_object_CHD','x_boolmat_test_{0}.txt'.format(target)), 'rb'))\r\n",
    "Y_BOOLMAT_TEST = pickle.load(open(os.path.join(output_folder,'pickled_object_CHD','y_boolmat_test_{0}.txt'.format(target)), 'rb'))\r\n",
    "print(Y_TEST.shape)\r\n",
    "\r\n",
    "m = return_loaded_model(model_name=\"ltsm_final_no_mask_Rein_pad14\",output_folder=output_folder)\r\n",
    "\r\n",
    "X_TEST_MASK = np.copy(X_TEST)\r\n",
    "X_TEST_MASK[X_BOOLMAT_TEST] = 0\r\n",
    "Y_PRED_mask_0 = m.predict(X_TEST_MASK)\r\n",
    "Y_CLASS = np.where(Y_PRED_mask_0[~Y_BOOLMAT_TEST] > 0.5, 1,0)\r\n",
    "fpr_b_base, tpr_b_base, thresholds_100 = roc_curve(Y_TEST[~Y_BOOLMAT_TEST], Y_PRED_mask_0[~Y_BOOLMAT_TEST])\r\n",
    "auc_b_base=roc_auc_score(Y_TEST[~Y_BOOLMAT_TEST], Y_PRED_mask_0[~Y_BOOLMAT_TEST])\r\n",
    "auc_b_base=round(auc_b_base,2)\r\n",
    "n_bootstraps = 2000\r\n",
    "rng_seed = 42  # control reproducibility\r\n",
    "bootstrapped_scores = []\r\n",
    "y_tes=Y_TEST\r\n",
    "Y_TEST=Y_TEST[~Y_BOOLMAT_TEST]\r\n",
    "y_pred_prob=Y_PRED_mask_0[~Y_BOOLMAT_TEST]\r\n",
    "rng = np.random.RandomState(rng_seed)\r\n",
    "for i in range(n_bootstraps):\r\n",
    "    # bootstrap by sampling with replacement on the prediction indices\r\n",
    "    indices = rng.randint(0, len(y_pred_prob), len(y_pred_prob))\r\n",
    "    if len(np.unique(Y_TEST[indices])) < 2:\r\n",
    "        # We need at least one positive and one negative sample for ROC AUC\r\n",
    "        # to be defined: reject the sample\r\n",
    "        continue\r\n",
    "\r\n",
    "    score = roc_auc_score(Y_TEST[indices], y_pred_prob[indices])\r\n",
    "    bootstrapped_scores.append(score)\r\n",
    "    #print(\"Bootstrap #{} ROC area: {:0.3f}\".format(i + 1, score))\r\n",
    "\r\n",
    "sorted_scores = np.array(bootstrapped_scores)\r\n",
    "sorted_scores.sort()\r\n",
    "\r\n",
    "# Computing the lower and upper bound of the 90% confidence interval\r\n",
    "# You can change the bounds percentiles to 0.025 and 0.975 to get\r\n",
    "# a 95% confidence interval instead.\r\n",
    "confidence_lower_b_base = round(sorted_scores[int(0.05 * len(sorted_scores))],2)\r\n",
    "confidence_upper_b_base = round(sorted_scores[int(0.95 * len(sorted_scores))],2)\r\n",
    "\r\n",
    "print(\"Brier score losses: (the smaller the better)\")\r\n",
    "\r\n",
    "clf_score = brier_score_loss(Y_TEST, y_pred_prob)\r\n",
    "print(\"No calibration: %1.3f\" % clf_score)\r\n",
    "#matrix = metrics.confusion_matrix(Y_TEST, Y_CLASS)\r\n",
    "average_precision = average_precision_score(Y_TEST, y_pred_prob)\r\n",
    "\r\n",
    "\r\n",
    "print(average_precision)\r\n",
    "report=classification_report(Y_TEST,Y_CLASS,target_names=['No Reintubation','Reintubation'])\r\n",
    "print(report)\r\n",
    "tn, fp, fn, tp=confusion_matrix(Y_TEST,Y_CLASS).ravel()\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(tn, fp, fn, tp)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from keras.models import Model, Input, load_model\r\n",
    "from RNN_LTSM_CHD import return_loaded_model\r\n",
    "\r\n",
    "output_folder = os.path.join(os.getcwd(), 'Results_RNN_v3', 'Adam')\r\n",
    "\r\n",
    "target = 'Reintub'\r\n",
    "X_TEST = pickle.load(open(os.path.join(output_folder,'pickled_object_CHD','X_TEST_{0}.txt'.format(target)), 'rb'))\r\n",
    "Y_TEST = pickle.load(open(os.path.join(output_folder,'pickled_object_CHD','Y_TEST_{0}.txt'.format(target)), 'rb'))\r\n",
    "X_BOOLMAT_TEST = pickle.load(open(os.path.join(output_folder,'pickled_object_CHD','x_boolmat_test_{0}.txt'.format(target)), 'rb'))\r\n",
    "Y_BOOLMAT_TEST = pickle.load(open(os.path.join(output_folder,'pickled_object_CHD','y_boolmat_test_{0}.txt'.format(target)), 'rb'))\r\n",
    "\r\n",
    "m = return_loaded_model(model_name=\"ltsm_final_no_mask_Rein_pad14\",output_folder=output_folder)\r\n",
    "\r\n",
    "X_TEST_MASK = np.copy(X_TEST)\r\n",
    "X_TEST_MASK[X_BOOLMAT_TEST] = 0\r\n",
    "Y_PRED_mask_0 = m.predict(X_TEST_MASK)\r\n",
    "del X_TEST_MASK\r\n",
    "\r\n",
    "fpr_b_adam, tpr_b_adam, thresholds_100 = roc_curve(Y_TEST[~Y_BOOLMAT_TEST], Y_PRED_mask_0[~Y_BOOLMAT_TEST])\r\n",
    "auc_b_adam=roc_auc_score(Y_TEST[~Y_BOOLMAT_TEST], Y_PRED_mask_0[~Y_BOOLMAT_TEST])\r\n",
    "auc_b_adam=round(auc_b_adam,2)\r\n",
    "n_bootstraps = 2000\r\n",
    "rng_seed = 42  # control reproducibility\r\n",
    "bootstrapped_scores = []\r\n",
    "Y_TEST=Y_TEST[~Y_BOOLMAT_TEST]\r\n",
    "y_pred_prob=Y_PRED_mask_0[~Y_BOOLMAT_TEST]\r\n",
    "rng = np.random.RandomState(rng_seed)\r\n",
    "for i in range(n_bootstraps):\r\n",
    "    # bootstrap by sampling with replacement on the prediction indices\r\n",
    "    indices = rng.randint(0, len(y_pred_prob), len(y_pred_prob))\r\n",
    "    if len(np.unique(Y_TEST[indices])) < 2:\r\n",
    "        # We need at least one positive and one negative sample for ROC AUC\r\n",
    "        # to be defined: reject the sample\r\n",
    "        continue\r\n",
    "\r\n",
    "    score = roc_auc_score(Y_TEST[indices], y_pred_prob[indices])\r\n",
    "    bootstrapped_scores.append(score)\r\n",
    "    #print(\"Bootstrap #{} ROC area: {:0.3f}\".format(i + 1, score))\r\n",
    "\r\n",
    "sorted_scores = np.array(bootstrapped_scores)\r\n",
    "sorted_scores.sort()\r\n",
    "\r\n",
    "# Computing the lower and upper bound of the 90% confidence interval\r\n",
    "# You can change the bounds percentiles to 0.025 and 0.975 to get\r\n",
    "# a 95% confidence interval instead.\r\n",
    "confidence_lower_b_adam = round(sorted_scores[int(0.05 * len(sorted_scores))],2)\r\n",
    "confidence_upper_b_adam = round(sorted_scores[int(0.95 * len(sorted_scores))],2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from keras.models import Model, Input, load_model\r\n",
    "from RNN_LTSM_CHD import return_loaded_model\r\n",
    "\r\n",
    "output_folder = os.path.join(os.getcwd(), 'Results_RNN_v3', 'Bid')\r\n",
    "\r\n",
    "target = 'Reintub'\r\n",
    "X_TEST = pickle.load(open(os.path.join(output_folder,'pickled_object_CHD','X_TEST_{0}.txt'.format(target)), 'rb'))\r\n",
    "Y_TEST = pickle.load(open(os.path.join(output_folder,'pickled_object_CHD','Y_TEST_{0}.txt'.format(target)), 'rb'))\r\n",
    "X_BOOLMAT_TEST = pickle.load(open(os.path.join(output_folder,'pickled_object_CHD','x_boolmat_test_{0}.txt'.format(target)), 'rb'))\r\n",
    "Y_BOOLMAT_TEST = pickle.load(open(os.path.join(output_folder,'pickled_object_CHD','y_boolmat_test_{0}.txt'.format(target)), 'rb'))\r\n",
    "\r\n",
    "m = return_loaded_model(model_name=\"ltsm_final_no_mask_Rein_pad14\",output_folder=output_folder)\r\n",
    "\r\n",
    "X_TEST_MASK = np.copy(X_TEST)\r\n",
    "X_TEST_MASK[X_BOOLMAT_TEST] = 0\r\n",
    "Y_PRED_mask_0 = m.predict(X_TEST_MASK)\r\n",
    "del X_TEST_MASK\r\n",
    "\r\n",
    "fpr_b_bid, tpr_b_bid, thresholds_100 = roc_curve(Y_TEST[~Y_BOOLMAT_TEST], Y_PRED_mask_0[~Y_BOOLMAT_TEST])\r\n",
    "auc_b_bid=roc_auc_score(Y_TEST[~Y_BOOLMAT_TEST], Y_PRED_mask_0[~Y_BOOLMAT_TEST])\r\n",
    "auc_b_bid=round(auc_b_bid,2)\r\n",
    "n_bootstraps = 2000\r\n",
    "rng_seed = 42  # control reproducibility\r\n",
    "bootstrapped_scores = []\r\n",
    "Y_TEST=Y_TEST[~Y_BOOLMAT_TEST]\r\n",
    "y_pred_prob=Y_PRED_mask_0[~Y_BOOLMAT_TEST]\r\n",
    "rng = np.random.RandomState(rng_seed)\r\n",
    "for i in range(n_bootstraps):\r\n",
    "    # bootstrap by sampling with replacement on the prediction indices\r\n",
    "    indices = rng.randint(0, len(y_pred_prob), len(y_pred_prob))\r\n",
    "    if len(np.unique(Y_TEST[indices])) < 2:\r\n",
    "        # We need at least one positive and one negative sample for ROC AUC\r\n",
    "        # to be defined: reject the sample\r\n",
    "        continue\r\n",
    "\r\n",
    "    score = roc_auc_score(Y_TEST[indices], y_pred_prob[indices])\r\n",
    "    bootstrapped_scores.append(score)\r\n",
    "    #print(\"Bootstrap #{} ROC area: {:0.3f}\".format(i + 1, score))\r\n",
    "\r\n",
    "sorted_scores = np.array(bootstrapped_scores)\r\n",
    "sorted_scores.sort()\r\n",
    "\r\n",
    "# Computing the lower and upper bound of the 90% confidence interval\r\n",
    "# You can change the bounds percentiles to 0.025 and 0.975 to get\r\n",
    "# a 95% confidence interval instead.\r\n",
    "confidence_lower_b_bid = round(sorted_scores[int(0.05 * len(sorted_scores))],2)\r\n",
    "confidence_upper_b_bid = round(sorted_scores[int(0.95 * len(sorted_scores))],2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from keras.models import Model, Input, load_model\r\n",
    "from RNN_LTSM_CHD import return_loaded_model\r\n",
    "\r\n",
    "output_folder = os.path.join(os.getcwd(), 'Results_RNN_v3', 'No Attention')\r\n",
    "\r\n",
    "target = 'Reintub'\r\n",
    "X_TEST = pickle.load(open(os.path.join(output_folder,'pickled_object_CHD','X_TEST_{0}.txt'.format(target)), 'rb'))\r\n",
    "Y_TEST = pickle.load(open(os.path.join(output_folder,'pickled_object_CHD','Y_TEST_{0}.txt'.format(target)), 'rb'))\r\n",
    "X_BOOLMAT_TEST = pickle.load(open(os.path.join(output_folder,'pickled_object_CHD','x_boolmat_test_{0}.txt'.format(target)), 'rb'))\r\n",
    "Y_BOOLMAT_TEST = pickle.load(open(os.path.join(output_folder,'pickled_object_CHD','y_boolmat_test_{0}.txt'.format(target)), 'rb'))\r\n",
    "\r\n",
    "m = return_loaded_model(model_name=\"ltsm_final_no_mask_Rein_pad14\",output_folder=output_folder)\r\n",
    "\r\n",
    "X_TEST_MASK = np.copy(X_TEST)\r\n",
    "X_TEST_MASK[X_BOOLMAT_TEST] = 0\r\n",
    "Y_PRED_mask_0 = m.predict(X_TEST_MASK)\r\n",
    "del X_TEST_MASK\r\n",
    "\r\n",
    "fpr_b_no, tpr_b_no, thresholds_100 = roc_curve(Y_TEST[~Y_BOOLMAT_TEST], Y_PRED_mask_0[~Y_BOOLMAT_TEST])\r\n",
    "auc_b_no=roc_auc_score(Y_TEST[~Y_BOOLMAT_TEST], Y_PRED_mask_0[~Y_BOOLMAT_TEST])\r\n",
    "auc_b_no=round(auc_b_no,2)\r\n",
    "n_bootstraps = 2000\r\n",
    "rng_seed = 42  # control reproducibility\r\n",
    "bootstrapped_scores = []\r\n",
    "Y_TEST=Y_TEST[~Y_BOOLMAT_TEST]\r\n",
    "y_pred_prob=Y_PRED_mask_0[~Y_BOOLMAT_TEST]\r\n",
    "rng = np.random.RandomState(rng_seed)\r\n",
    "for i in range(n_bootstraps):\r\n",
    "    # bootstrap by sampling with replacement on the prediction indices\r\n",
    "    indices = rng.randint(0, len(y_pred_prob), len(y_pred_prob))\r\n",
    "    if len(np.unique(Y_TEST[indices])) < 2:\r\n",
    "        # We need at least one positive and one negative sample for ROC AUC\r\n",
    "        # to be defined: reject the sample\r\n",
    "        continue\r\n",
    "\r\n",
    "    score = roc_auc_score(Y_TEST[indices], y_pred_prob[indices])\r\n",
    "    bootstrapped_scores.append(score)\r\n",
    "    #print(\"Bootstrap #{} ROC area: {:0.3f}\".format(i + 1, score))\r\n",
    "\r\n",
    "sorted_scores = np.array(bootstrapped_scores)\r\n",
    "sorted_scores.sort()\r\n",
    "\r\n",
    "# Computing the lower and upper bound of the 90% confidence interval\r\n",
    "# You can change the bounds percentiles to 0.025 and 0.975 to get\r\n",
    "# a 95% confidence interval instead.\r\n",
    "confidence_lower_b_no = round(sorted_scores[int(0.05 * len(sorted_scores))],2)\r\n",
    "confidence_upper_b_no = round(sorted_scores[int(0.95 * len(sorted_scores))],2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from keras.models import Model, Input, load_model\r\n",
    "from RNN_LTSM_CHD import return_loaded_model\r\n",
    "\r\n",
    "output_folder = os.path.join(os.getcwd(), 'Results_RNN_v3', 'GRU')\r\n",
    "\r\n",
    "target = 'Reintub'\r\n",
    "X_TEST = pickle.load(open(os.path.join(output_folder,'pickled_object_CHD','X_TEST_{0}.txt'.format(target)), 'rb'))\r\n",
    "Y_TEST = pickle.load(open(os.path.join(output_folder,'pickled_object_CHD','Y_TEST_{0}.txt'.format(target)), 'rb'))\r\n",
    "X_BOOLMAT_TEST = pickle.load(open(os.path.join(output_folder,'pickled_object_CHD','x_boolmat_test_{0}.txt'.format(target)), 'rb'))\r\n",
    "Y_BOOLMAT_TEST = pickle.load(open(os.path.join(output_folder,'pickled_object_CHD','y_boolmat_test_{0}.txt'.format(target)), 'rb'))\r\n",
    "\r\n",
    "m = return_loaded_model(model_name=\"ltsm_final_no_mask_Rein_pad14\",output_folder=output_folder)\r\n",
    "\r\n",
    "X_TEST_MASK = np.copy(X_TEST)\r\n",
    "X_TEST_MASK[X_BOOLMAT_TEST] = 0\r\n",
    "Y_PRED_mask_0 = m.predict(X_TEST_MASK)\r\n",
    "del X_TEST_MASK\r\n",
    "\r\n",
    "fpr_b_gru, tpr_b_gru, thresholds_100 = roc_curve(Y_TEST[~Y_BOOLMAT_TEST], Y_PRED_mask_0[~Y_BOOLMAT_TEST])\r\n",
    "auc_b_gru=roc_auc_score(Y_TEST[~Y_BOOLMAT_TEST], Y_PRED_mask_0[~Y_BOOLMAT_TEST])\r\n",
    "auc_b_gru=round(auc_b_gru,2)\r\n",
    "n_bootstraps = 2000\r\n",
    "rng_seed = 42  # control reproducibility\r\n",
    "bootstrapped_scores = []\r\n",
    "Y_TEST=Y_TEST[~Y_BOOLMAT_TEST]\r\n",
    "y_pred_prob=Y_PRED_mask_0[~Y_BOOLMAT_TEST]\r\n",
    "rng = np.random.RandomState(rng_seed)\r\n",
    "for i in range(n_bootstraps):\r\n",
    "    # bootstrap by sampling with replacement on the prediction indices\r\n",
    "    indices = rng.randint(0, len(y_pred_prob), len(y_pred_prob))\r\n",
    "    if len(np.unique(Y_TEST[indices])) < 2:\r\n",
    "        # We need at least one positive and one negative sample for ROC AUC\r\n",
    "        # to be defined: reject the sample\r\n",
    "        continue\r\n",
    "\r\n",
    "    score = roc_auc_score(Y_TEST[indices], y_pred_prob[indices])\r\n",
    "    bootstrapped_scores.append(score)\r\n",
    "    #print(\"Bootstrap #{} ROC area: {:0.3f}\".format(i + 1, score))\r\n",
    "\r\n",
    "sorted_scores = np.array(bootstrapped_scores)\r\n",
    "sorted_scores.sort()\r\n",
    "\r\n",
    "# Computing the lower and upper bound of the 90% confidence interval\r\n",
    "# You can change the bounds percentiles to 0.025 and 0.975 to get\r\n",
    "# a 95% confidence interval instead.\r\n",
    "confidence_lower_b_gru = round(sorted_scores[int(0.05 * len(sorted_scores))],2)\r\n",
    "confidence_upper_b_gru = round(sorted_scores[int(0.95 * len(sorted_scores))],2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from keras.models import Model, Input, load_model\r\n",
    "from RNN_LTSM_CHD import return_loaded_model\r\n",
    "\r\n",
    "output_folder = os.path.join(os.getcwd(), 'Results_RNN_v3', 'SimpleRNN')\r\n",
    "\r\n",
    "target = 'Reintub'\r\n",
    "X_TEST = pickle.load(open(os.path.join(output_folder,'pickled_object_CHD','X_TEST_{0}.txt'.format(target)), 'rb'))\r\n",
    "Y_TEST = pickle.load(open(os.path.join(output_folder,'pickled_object_CHD','Y_TEST_{0}.txt'.format(target)), 'rb'))\r\n",
    "X_BOOLMAT_TEST = pickle.load(open(os.path.join(output_folder,'pickled_object_CHD','x_boolmat_test_{0}.txt'.format(target)), 'rb'))\r\n",
    "Y_BOOLMAT_TEST = pickle.load(open(os.path.join(output_folder,'pickled_object_CHD','y_boolmat_test_{0}.txt'.format(target)), 'rb'))\r\n",
    "\r\n",
    "m = return_loaded_model(model_name=\"ltsm_final_no_mask_Rein_pad14\",output_folder=output_folder)\r\n",
    "\r\n",
    "X_TEST_MASK = np.copy(X_TEST)\r\n",
    "X_TEST_MASK[X_BOOLMAT_TEST] = 0\r\n",
    "Y_PRED_mask_0 = m.predict(X_TEST_MASK)\r\n",
    "del X_TEST_MASK\r\n",
    "\r\n",
    "fpr_b_sim, tpr_b_sim, thresholds_100 = roc_curve(Y_TEST[~Y_BOOLMAT_TEST], Y_PRED_mask_0[~Y_BOOLMAT_TEST])\r\n",
    "auc_b_sim=roc_auc_score(Y_TEST[~Y_BOOLMAT_TEST], Y_PRED_mask_0[~Y_BOOLMAT_TEST])\r\n",
    "auc_b_sim=round(auc_b_sim,2)\r\n",
    "n_bootstraps = 2000\r\n",
    "rng_seed = 42  # control reproducibility\r\n",
    "bootstrapped_scores = []\r\n",
    "Y_TEST=Y_TEST[~Y_BOOLMAT_TEST]\r\n",
    "y_pred_prob=Y_PRED_mask_0[~Y_BOOLMAT_TEST]\r\n",
    "rng = np.random.RandomState(rng_seed)\r\n",
    "for i in range(n_bootstraps):\r\n",
    "    # bootstrap by sampling with replacement on the prediction indices\r\n",
    "    indices = rng.randint(0, len(y_pred_prob), len(y_pred_prob))\r\n",
    "    if len(np.unique(Y_TEST[indices])) < 2:\r\n",
    "        # We need at least one positive and one negative sample for ROC AUC\r\n",
    "        # to be defined: reject the sample\r\n",
    "        continue\r\n",
    "\r\n",
    "    score = roc_auc_score(Y_TEST[indices], y_pred_prob[indices])\r\n",
    "    bootstrapped_scores.append(score)\r\n",
    "    #print(\"Bootstrap #{} ROC area: {:0.3f}\".format(i + 1, score))\r\n",
    "\r\n",
    "sorted_scores = np.array(bootstrapped_scores)\r\n",
    "sorted_scores.sort()\r\n",
    "\r\n",
    "# Computing the lower and upper bound of the 90% confidence interval\r\n",
    "# You can change the bounds percentiles to 0.025 and 0.975 to get\r\n",
    "# a 95% confidence interval instead.\r\n",
    "confidence_lower_b_sim = round(sorted_scores[int(0.05 * len(sorted_scores))],2)\r\n",
    "confidence_upper_b_sim = round(sorted_scores[int(0.95 * len(sorted_scores))],2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "output_folder=os.path.join(os.getcwd(),'Result_ROC_curves')\r\n",
    "pdf_ROC = PdfPages(os.path.join(output_folder,f\"ROC of bron RNN.pdf\"))\r\n",
    "plt.plot(fpr_b_base, tpr_b_base,'k--',label=f\"Base RNN-LSTM, AUC={auc_b_base} [{confidence_lower_b_base} - {confidence_upper_b_base}]\",linewidth=.7,markersize=1)\r\n",
    "plt.plot(fpr_b_adam, tpr_b_adam,'c-.',label=f\"RNN-LSTM with adam optimizer, AUC={auc_b_adam} [{confidence_lower_b_adam} - {confidence_upper_b_adam}]\",linewidth=.7,markersize=1)\r\n",
    "plt.plot(fpr_b_bid, tpr_b_bid,'b-',label=f\"Bidirectional RNN-LSTM, AUC={auc_b_bid} [{confidence_lower_b_bid} - {confidence_upper_b_bid}]\",linewidth=.7,markersize=1)\r\n",
    "plt.plot(fpr_b_sim, tpr_b_sim,'r:',label=f\"only RNN layer, AUC={auc_b_sim} [{confidence_lower_b_sim} - {confidence_upper_b_sim}]\",linewidth=.7,markersize=1)\r\n",
    "plt.plot(fpr_b_gru, tpr_b_gru,'m-',label=f\"RNN with GRU layer, AUC={auc_b_gru} [{confidence_lower_b_gru} - {confidence_upper_b_gru}]\",linewidth=.7,markersize=1)\r\n",
    "plt.plot(fpr_b_no, tpr_b_no,'g-.',label=f\"RNN-LSTM without attention layer, AUC={auc_b_no} [{confidence_lower_b_no} - {confidence_upper_b_no}]\",linewidth=.7,markersize=1)\r\n",
    "\r\n",
    "\r\n",
    "plt.legend(loc=4,fontsize='xx-small')\r\n",
    "plt.title(f'ROC of different RNNs on bronchiolitis cohort')\r\n",
    "plt.xlabel('False Positive Rate')\r\n",
    "plt.ylabel('True Positive Rate')\r\n",
    "axes = plt.gca()\r\n",
    "axes.set_xlim([0,1])\r\n",
    "axes.set_ylim([0,1])\r\n",
    "fig=plt.gcf()\r\n",
    "pdf_ROC.savefig(fig)\r\n",
    "plt.show(fig)\r\n",
    "plt.close(fig)\r\n",
    "pdf_ROC.close()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}