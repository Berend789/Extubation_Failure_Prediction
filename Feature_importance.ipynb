{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "3b7e431a861a72513f361682db481bb043ab213b57189a56d42fe6b32fa57c58"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\berend\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\nC:\\Users\\berend\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\nC:\\Users\\berend\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\nC:\\Users\\berend\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from all_stand_var import conv_dict, lab_cols, vent_cols3\n",
    "from all_own_funct import memory_downscale,memory_upscale\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "from seaborn import heatmap\n",
    "from sklearn.metrics import roc_curve, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from scipy.stats import kurtosis\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import keras.backend as K\n",
    "from RNN_LTSM_CHD import return_loaded_model\n",
    "import pickle\n",
    "import locale\n",
    "import LR_build_CHD as pp\n",
    "import tables\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import roc_curve, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "locale.setlocale(locale.LC_ALL, 'fr_FR')\n",
    "output_folder = os.path.join(os.getcwd(), 'Results_LR_RF_CHD_v2','Static')\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "    \n",
    "\n",
    "f = open(os.path.join(output_folder,'ran_for.sav'), 'rb')\n",
    "best_rf=pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(os.path.join(output_folder,'log_reg.sav'), 'rb')\n",
    "best_lr=pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import tables\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "df=pd.read_hdf(os.path.join('./Results_CHD/', 'processed_df.h5'),key='df',mode='r')\n",
    "#df=memory_downscale(df)\n",
    "print(df.info())\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "df=df.reset_index(drop=False)\n",
    "df.info()\n",
    "def index_1hr(group):\n",
    "    if len(group) > 720:\n",
    "        group=group.sort_values('pat_datetime')\n",
    "        group=group.tail(720)\n",
    "    group['tim']=pd.date_range(start='1/1/2018', periods=len(group), freq='1min')\n",
    "    grouped = pd.Grouper(key='tim', freq='1H')\n",
    "    group['idx_1hr']=group.groupby(grouped,sort=False).ngroup().add(1)\n",
    "    #group['mis']=(group['pat_datetime'].max()-group['pat_datetime'].min()).total_seconds()/60\n",
    "    del group['tim']\n",
    "    return group\n",
    "#grouped = pd.Grouper(key='pat_datetime', freq='60min',label='left',convention='start')\n",
    "#df['idx_1hr']=df.groupby(['Adnum','pat_hosp_id','AdmissionDate','DischargeDate'],sort=False,as_index=False).ngroup().add(1)\n",
    "df=df.groupby('Adnum',sort=False,as_index=False).apply(index_1hr)\n",
    "df['idx_1hr']=df['idx_1hr'].astype(str)\n",
    "print(df['idx_1hr'].unique())\n",
    "#df[['mis']]=StandardScaler().fit_transform(df[['mis']])\n",
    "df=df.set_index(['pat_hosp_id','OK_datum'])\n",
    "\n",
    "\n",
    "\n",
    "pat=pd.read_excel(r'Results_CHD\\admissiondate_CHD0.xlsx',\n",
    "                    parse_dates=['OK_datum'],index_col=0)\n",
    "group=pat.groupby('pat_hosp_id',sort=False).max().reset_index()\n",
    "group.drop_duplicates('pat_hosp_id',inplace=True)\n",
    "\n",
    "df_train,df_val,df_test=pp.split_stratified_into_train_val_test(group, stratify_colname='Reintub',\n",
    "                                         frac_train=0.7, frac_val=0.1, frac_test=0.2,\n",
    "                                         random_state=1)\n",
    "\n",
    "train_pat=df_train['pat_hosp_id'].unique()\n",
    "test_pat=df_test['pat_hosp_id'].unique()\n",
    "val_pat=df_val['pat_hosp_id'].unique()\n",
    "\n",
    "df_train = df[df.index.get_level_values('pat_hosp_id').isin(train_pat)]\n",
    "df_val = df[df.index.get_level_values('pat_hosp_id').isin(val_pat)]\n",
    "df_test = df[df.index.get_level_values('pat_hosp_id').isin(test_pat)]\n",
    "print(df_train.info())\n",
    "print(df_test.info())\n",
    "\n",
    "def x_modelling(df):\n",
    "    temp = df[['Age', 'Adnum', 'idx_1hr','pat_weight_act','Diagnose']]\n",
    "    df = df.drop(['Age','pat_weight_act','Extubation_date','level_0','pat_datetime', 'Reintub','Diagnose'], axis=1)\n",
    "    df = df.groupby(['Adnum', 'idx_1hr'], sort=False).agg(['mean', 'std'])\n",
    "    df.columns = [\"_\".join(a) for a in df.columns.to_flat_index()]\n",
    "    df = df.stack().unstack([2, 1])\n",
    "    df.columns = [\"_\".join(a) for a in df.columns.to_flat_index()]\n",
    "    df = df.reset_index().drop_duplicates().set_index('Adnum')\n",
    "    df = df.fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "    temp = temp.groupby('Adnum', sort=False).agg(['mean'])\n",
    "    temp.columns = [\"_\".join(a) for a in temp.columns.to_flat_index()]\n",
    "    temp = temp.reset_index().drop_duplicates().set_index('Adnum')\n",
    "    temp = temp[~temp.index.duplicated(keep='last')]\n",
    "    df = df.merge(temp, right_index=True, left_index=True, how='left')\n",
    "    return df\n",
    "X_TRAIN=memory_upscale(x_modelling(df_train))\n",
    "X_TEST=memory_upscale(x_modelling(df_test))\n",
    "X_VAL=memory_upscale(x_modelling(df_val))\n",
    "print(X_TRAIN.info())\n",
    "print(X_TEST.info())\n",
    "X_TRAIN=X_TRAIN.fillna(method='ffill').fillna(method='bfill')\n",
    "X_VAL=X_VAL.fillna(method='ffill').fillna(method='bfill')\n",
    "X_TEST=X_TEST.fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "X_TRAIN=X_TRAIN.append(X_VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_modelling(df):\n",
    "    y = df[['Reintub', 'Adnum', 'idx_1hr']]\n",
    "    y = y.groupby(['Adnum', 'idx_1hr'], sort=False).agg(['max'])\n",
    "    y.columns = [\"_\".join(a) for a in y.columns.to_flat_index()]\n",
    "    y.reset_index(drop=True, inplace=True, level='idx_1hr')\n",
    "    y = y.reset_index().drop_duplicates().set_index(\n",
    "        ['Adnum'])\n",
    "    y = y[~y.index.duplicated(keep='last')]\n",
    "    return y\n",
    "Y_TRAIN=y_modelling(df_train)\n",
    "Y_TEST=y_modelling(df_test)\n",
    "Y_VAL=y_modelling(df_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['mis_mean', 'pat_weight_act_mean', 'Age_mean', 'Diagnose_mean']\n"
     ]
    }
   ],
   "source": [
    "clf=best_lr\n",
    "f = open(os.path.join(output_folder, 'cols.pkl'), 'rb')\n",
    "float_columns = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "print(float_columns)\n",
    "try:\n",
    "    pdf = PdfPages(os.path.join(output_folder,f\"Figures_importance_prob.pdf\"))\n",
    "except PermissionError:\n",
    "    os.remove(os.path.join(output_folder,f\"Figures_importance_prob.pdf\"))\n",
    "\n",
    "try:\n",
    "    coefs = clf.coef_.flatten()\n",
    "except:\n",
    "    coefs=clf.feature_importances_\n",
    "\n",
    "# Zip coefficients and names together and make a DataFrame\n",
    "zipped = zip(float_columns, coefs)\n",
    "df = pd.DataFrame(zipped, columns=[\"feature\", \"value\"])\n",
    "# Sort the features by the absolute value of their coefficient\n",
    "df[\"abs_value\"] = df[\"value\"].apply(lambda x: abs(x))\n",
    "df[\"colors\"] = df[\"value\"].apply(lambda x: \"green\" if x > 0 else \"red\")\n",
    "df = df.sort_values(\"abs_value\", ascending=False)\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "fig, ax = plt.subplots(1, 1,figsize=(16,16))\n",
    "sns.barplot(x=\"feature\",\n",
    "            y=\"value\",\n",
    "            data=df.head(20),\n",
    "            palette=df.head(20)[\"colors\"])\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=65, fontsize=10)\n",
    "ax.set_title(\"Top 20 Features, LR\", fontsize=12)\n",
    "ax.set_ylabel(\"Coef\", fontsize=12)\n",
    "ax.set_xlabel(\"Feature Name\", fontsize=12)\n",
    "fig=plt.gcf()\n",
    "pdf.savefig(fig)\n",
    "plt.close(fig) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['pat_weight_act_mean', 'mis_mean', 'Diagnose_mean', 'Age_mean']\n"
     ]
    }
   ],
   "source": [
    "clf=best_rf\n",
    "\n",
    "try:\n",
    "    coefs = clf.coef_.flatten()\n",
    "except:\n",
    "    coefs=clf.feature_importances_\n",
    "\n",
    "# Zip coefficients and names together and make a DataFrame\n",
    "zipped = zip(float_columns, coefs)\n",
    "df = pd.DataFrame(zipped, columns=[\"feature\", \"value\"])\n",
    "# Sort the features by the absolute value of their coefficient\n",
    "df[\"abs_value\"] = df[\"value\"].apply(lambda x: abs(x))\n",
    "df[\"colors\"] = df[\"value\"].apply(lambda x: \"green\" if x > 0 else \"red\")\n",
    "df = df.sort_values(\"abs_value\", ascending=False)\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "sns.barplot(x=\"feature\",\n",
    "            y=\"value\",\n",
    "            data=df.head(30),\n",
    "            palette=df.head(30)[\"colors\"])\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=65, fontsize=10)\n",
    "ax.set_title(\"Top 20 Features, RF\", fontsize=12)\n",
    "ax.set_ylabel(\"Coef\", fontsize=12)\n",
    "ax.set_xlabel(\"Feature Name\", fontsize=12)\n",
    "print(df[\"feature\"].head(20).tolist())\n",
    "plt.tight_layout()\n",
    "fig=plt.gcf()\n",
    "pdf.savefig(fig)\n",
    "plt.close(fig) \n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_TEST.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=best_lr.predict_proba(X_TEST)[:,1]\n",
    "#print(prediction)\n",
    "true_0 = (Y_TEST == 0.0)\n",
    "true_1 = (Y_TEST == 1.0)\n",
    "df_test=pd.DataFrame()\n",
    "df_test['prob']=best_lr.predict_proba(X_TEST)[:,1]\n",
    "df_test['true']=Y_TEST\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.hist(df_test['prob'].loc[df_test['true']==0], bins=50, label='Negatives')\n",
    "plt.hist(df_test['prob'].loc[df_test['true']==1], bins=50, label='Positives', alpha=0.7, color='r')\n",
    "plt.xlabel('Probability of being Positive Class', fontsize=25)\n",
    "plt.ylabel('Number of records in each bucket', fontsize=25)\n",
    "plt.title('Probability distribution of best LR')\n",
    "plt.legend(fontsize=15)\n",
    "plt.tick_params(axis='both', labelsize=25, pad=5)\n",
    "plt.show()\n",
    "plt.tight_layout()\n",
    "fig=plt.gcf()\n",
    "pdf.savefig(fig)\n",
    "plt.close(fig) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=best_rf.predict_proba(X_TRAIN)[:,1]\n",
    "true_0 = (Y_TEST == 0.0)\n",
    "true_1 = (Y_TEST == 1.0)\n",
    "df_test=pd.DataFrame()\n",
    "df_test['prob']=best_rf.predict_proba(X_TEST)[:,1]\n",
    "df_test['true']=Y_TEST\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.hist(df_test['prob'].loc[df_test['true']==0], bins=50, label='Negatives')\n",
    "plt.hist(df_test['prob'].loc[df_test['true']==1], bins=50, label='Positives', alpha=0.8, color='r')\n",
    "plt.xlabel('Probability of being Positive Class', fontsize=25)\n",
    "plt.ylabel('Number of records in each bucket', fontsize=25)\n",
    "plt.title('Probability distribution of best RF')\n",
    "plt.legend(fontsize=15)\n",
    "plt.tick_params(axis='both', labelsize=25, pad=5)\n",
    "plt.show()\n",
    "fig=plt.gcf()\n",
    "pdf.savefig(fig)\n",
    "plt.close(fig)\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}