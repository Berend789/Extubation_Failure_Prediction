{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "3b7e431a861a72513f361682db481bb043ab213b57189a56d42fe6b32fa57c58"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\berend\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\nC:\\Users\\berend\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\nC:\\Users\\berend\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\nC:\\Users\\berend\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from all_stand_var import conv_dict, vent_cols3\n",
    "from all_own_funct import memory_downscale,memory_upscale,evaluate\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "from seaborn import heatmap\n",
    "from sklearn.metrics import roc_curve, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from scipy.stats import kurtosis\n",
    "from sklearn.metrics import roc_curve, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import locale\n",
    "import pickle\n",
    "locale.setlocale(locale.LC_ALL, 'fr_FR')\n",
    "output_folder = os.path.join(os.getcwd(), 'Results_LR_RF_v2','Table')\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vent_cols3 = ['pat_hosp_id', 'pat_bd', 'pat_datetime', 'AdmissionDate','DischargeDate', 'mon_rr', 'mon_hr', 'mon_sat',\n",
    "              'mon_etco2', 'vent_m_fio2', 'vent_m_ppeak','vent_m_peep',\n",
    "             'mon_ibp_mean','pat_weight_act','vent_m_rr', 'vent_m_tv_exp']\n",
    "dtype_dict={'vent_cat': 'category','vent_machine':'category','vent_mode':'category'}\n",
    "df_raw=pd.read_csv(r'data\\sorted_bron_date.csv',delimiter=';',converters=conv_dict,usecols=vent_cols3,dtype=dtype_dict,parse_dates=['pat_bd','pat_datetime','AdmissionDate', 'DischargeDate'],na_values=['NULL','null', 'Null','nUll','nuLl','nulL'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "394\n",
      "c:\\Users\\berend\\Documents\\Python_Scripts\\Patient_Selection\\LR_build.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['pat_datetime_temp'] = pd.to_datetime(df['pat_datetime']).dt.date\n",
      "c:\\Users\\berend\\Documents\\Python_Scripts\\Patient_Selection\\LR_build.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['pat_bd'] = pd.to_datetime(df['pat_bd']).dt.date\n",
      "c:\\Users\\berend\\Documents\\Python_Scripts\\Patient_Selection\\LR_build.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['pat_bd']).dt.days.divide(365)\n",
      "count    3.409311e+06\n",
      "mean     3.840034e-01\n",
      "std      6.091721e-01\n",
      "min      0.000000e+00\n",
      "25%      9.315068e-02\n",
      "50%      1.479452e-01\n",
      "75%      3.753425e-01\n",
      "max      5.117808e+00\n",
      "Name: Age, dtype: float64\n",
      "38\n",
      "327\n",
      "mergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmergmerg\n",
      "38\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 3409311 entries, (5379, Timestamp('2012-11-27 19:00:00'), Timestamp('2012-12-07 10:15:00')) to (9986307, Timestamp('2014-01-09 11:30:00'), Timestamp('2014-01-17 14:20:00'))\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Dtype         \n",
      "---  ------           -----         \n",
      " 0   pat_datetime     datetime64[ns]\n",
      " 1   pat_weight_act   float32       \n",
      " 2   mon_etco2        float32       \n",
      " 3   mon_hr           float32       \n",
      " 4   mon_ibp_mean     float32       \n",
      " 5   mon_rr           float32       \n",
      " 6   mon_sat          float32       \n",
      " 7   vent_m_fio2      float32       \n",
      " 8   vent_m_peep      float32       \n",
      " 9   vent_m_ppeak     float32       \n",
      " 10  vent_m_rr        float32       \n",
      " 11  vent_m_tv_exp    float32       \n",
      " 12  Adnum            int64         \n",
      " 13  Age              float32       \n",
      " 14  Reintub          int64         \n",
      " 15  Extubation_date  datetime64[ns]\n",
      "dtypes: datetime64[ns](2), float32(12), int64(2)\n",
      "memory usage: 279.6 MB\n",
      "None\n",
      "326\n",
      "Trim\n",
      "37\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 230072 entries, (88, 2481139, Timestamp('2008-11-03 14:00:00'), Timestamp('2008-11-22 15:28:00')) to (206, 6611048, Timestamp('2019-12-23 20:35:00'), Timestamp('2020-01-07 11:30:00'))\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count   Dtype         \n",
      "---  ------           --------------   -----         \n",
      " 0   pat_datetime     230072 non-null  datetime64[ns]\n",
      " 1   pat_weight_act   230072 non-null  float32       \n",
      " 2   mon_etco2        168135 non-null  float32       \n",
      " 3   mon_hr           228495 non-null  float32       \n",
      " 4   mon_ibp_mean     102556 non-null  float32       \n",
      " 5   mon_rr           223194 non-null  float32       \n",
      " 6   mon_sat          226919 non-null  float32       \n",
      " 7   vent_m_fio2      225617 non-null  float32       \n",
      " 8   vent_m_peep      223351 non-null  float32       \n",
      " 9   vent_m_ppeak     229217 non-null  float32       \n",
      " 10  vent_m_rr        229999 non-null  float32       \n",
      " 11  vent_m_tv_exp    226006 non-null  float32       \n",
      " 12  Adnum            230072 non-null  int64         \n",
      " 13  Age              230072 non-null  float32       \n",
      " 14  Reintub          230072 non-null  int64         \n",
      " 15  Extubation_date  230072 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](2), float32(12), int64(2)\n",
      "memory usage: 19.3 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import LR_build as pp\n",
    "importlib.reload(pp)\n",
    "df = pp.data_pp_function(df_raw,path=output_folder,timestep='12H')\n",
    "#df=df.groupby('Admissionnumber',sort=False).fillna(method='ffill').fillna(method='bfill')\n",
    "#f = open(os.path.join('./Results_LR_RF_v2/', 'processed_df.txt'), 'rb')\n",
    "#df = pickle.load(f)\n",
    "#f.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                                   | 90.5        |           | 1 (0.0)      | 1 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 90.6        |           | 2 (0.0)      | 2 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 90.7        |           | 1 (0.0)      | 1 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 90.8        |           | 3 (0.0)      | 2 (0.0)      | 1 (0.0)     |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 90.9        |           | 3 (0.0)      | 3 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 91.0        |           | 43 (0.0)     | 42 (0.0)     | 1 (0.0)     |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 91.1        |           | 1 (0.0)      | 1 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 91.2        |           | 4 (0.0)      | 4 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 91.3        |           | 5 (0.0)      | 5 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 91.5        |           | 1 (0.0)      | 1 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 91.6        |           | 3 (0.0)      | 3 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 91.7        |           | 5 (0.0)      | 5 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 91.9        |           | 2 (0.0)      | 1 (0.0)      | 1 (0.0)     |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 92.0        |           | 19 (0.0)     | 18 (0.0)     | 1 (0.0)     |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 92.1        |           | 6 (0.0)      | 6 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 92.2        |           | 2 (0.0)      | 2 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 92.4        |           | 2 (0.0)      | 2 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 92.5        |           | 1 (0.0)      | 1 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 92.6        |           | 4 (0.0)      | 4 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 92.7        |           | 3 (0.0)      | 3 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 92.9        |           | 2 (0.0)      | 1 (0.0)      | 1 (0.0)     |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 93.0        |           | 29 (0.0)     | 29 (0.0)     |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 93.1        |           | 2 (0.0)      | 2 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 93.2        |           | 2 (0.0)      | 2 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 93.3        |           | 1 (0.0)      | 1 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 93.4        |           | 1 (0.0)      | 1 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 93.5        |           | 1 (0.0)      | 1 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 93.6        |           | 2 (0.0)      | 2 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 93.7        |           | 1 (0.0)      | 1 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 93.8        |           | 1 (0.0)      | 1 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 93.9        |           | 2 (0.0)      | 2 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 94.0        |           | 28 (0.0)     | 27 (0.0)     | 1 (0.0)     |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 94.2        |           | 1 (0.0)      | 1 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 94.4        |           | 1 (0.0)      | 1 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 94.5        |           | 2 (0.0)      | 2 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 94.7        |           | 2 (0.0)      | 2 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 94.8        |           | 1 (0.0)      | 1 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 95.0        |           | 34 (0.0)     | 34 (0.0)     |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 95.1        |           | 3 (0.0)      | 3 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 95.2        |           | 2 (0.0)      | 2 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 95.3        |           | 2 (0.0)      | 2 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 95.4        |           | 3 (0.0)      | 3 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 95.5        |           | 1 (0.0)      | 1 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 95.6        |           | 2 (0.0)      | 2 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 95.7        |           | 1 (0.0)      | 1 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 95.8        |           | 1 (0.0)      | 1 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 95.9        |           | 1 (0.0)      | 1 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 96.0        |           | 19 (0.0)     | 19 (0.0)     |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 96.2        |           | 2 (0.0)      | 2 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 96.4        |           | 2 (0.0)      | 2 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 96.5        |           | 1 (0.0)      | 1 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 96.6        |           | 1 (0.0)      | 1 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 96.7        |           | 1 (0.0)      | 1 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 96.8        |           | 1 (0.0)      | 1 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 96.9        |           | 2 (0.0)      | 2 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 97.0        |           | 21 (0.0)     | 21 (0.0)     |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 97.2        |           | 1 (0.0)      | 1 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 97.8        |           | 2 (0.0)      | 2 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 97.9        |           | 2 (0.0)      | 2 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 98.0        |           | 25 (0.0)     | 24 (0.0)     | 1 (0.0)     |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 98.1        |           | 2 (0.0)      |              | 2 (0.0)     |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 98.2        |           | 2 (0.0)      | 2 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 98.3        |           | 1 (0.0)      | 1 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 98.4        |           | 1 (0.0)      | 1 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 98.5        |           | 1 (0.0)      | 1 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 98.7        |           | 3 (0.0)      | 3 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 99.0        |           | 20 (0.0)     | 20 (0.0)     |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 99.1        |           | 1 (0.0)      | 1 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 99.3        |           | 2 (0.0)      | 2 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 99.5        |           | 2 (0.0)      | 1 (0.0)      | 1 (0.0)     |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 99.7        |           | 1 (0.0)      | 1 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "|                                                    | 99.8        |           | 2 (0.0)      | 2 (0.0)      |             |           |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n",
      "| Ventilator expiratory tidal volume (mL), mean (SD) |             | 4066      | 34.1 (30.4)  | 33.5 (30.8)  | 39.1 (26.8) | <0.001    |\n",
      "+----------------------------------------------------+-------------+-----------+--------------+--------------+-------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "from tableone import TableOne\n",
    "from all_stand_var import rename_dict\n",
    "#del rename_dict['Diagnose']\n",
    "\n",
    "df_temp=df.reset_index(drop=True)\n",
    "df_temp=df_temp.rename(columns=rename_dict)\n",
    "print(df_temp.info())\n",
    "columns= list(rename_dict.values())\n",
    "\n",
    "mytable=TableOne(df_temp,columns=columns,groupby='Reintub',pval=True)\n",
    "print(mytable.tabulate(tablefmt=\"grid\"))\n",
    "mytable.to_excel(os.path.join('./Results','Table_1_raw.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0      720\n",
      "208    720\n",
      "84     720\n",
      "339    720\n",
      "338    720\n",
      "      ... \n",
      "306    240\n",
      "47      65\n",
      "76      28\n",
      "284     10\n",
      "383      1\n",
      "Name: Adnum, Length: 327, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 327 entries, 104 to 246\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   pat_weight_act  327 non-null    float32\n",
      " 1   mon_etco2       327 non-null    float32\n",
      " 2   mon_hr          327 non-null    float32\n",
      " 3   mon_ibp_mean    327 non-null    float32\n",
      " 4   mon_rr          327 non-null    float32\n",
      " 5   mon_sat         327 non-null    float32\n",
      " 6   vent_m_fio2     327 non-null    float32\n",
      " 7   vent_m_peep     327 non-null    float32\n",
      " 8   vent_m_ppeak    327 non-null    float32\n",
      " 9   vent_m_rr       327 non-null    float32\n",
      " 10  vent_m_tv_exp   327 non-null    float32\n",
      " 11  Age             327 non-null    float32\n",
      " 12  Reintub         327 non-null    int64  \n",
      " 13  Time gap (min)  327 non-null    float64\n",
      "dtypes: float32(12), float64(1), int64(1)\n",
      "memory usage: 23.0 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df=df.reset_index(drop=True)\n",
    "def index_1hr(group):\n",
    "    #grouped = pd.Grouper(key='pat_datetime', freq='1H')\n",
    "    #group['idx_1hr']=group.groupby(grouped,sort=False).ngroup().add(1)\n",
    "    #group['idx_1hr']=group['idx_1hr'].apply(str)\n",
    "    group['Time gap (min)'] = group['pat_datetime'].max()-group['pat_datetime'].min()\n",
    "    group['Time gap (min)'] = group['Time gap (min)'].dt.seconds.divide(60)\n",
    "    return group\n",
    "#df.reset_index(drop=True,inplace=True)\n",
    "df=df.groupby('Adnum',sort=False,as_index=False).apply(index_1hr)\n",
    "print((df['Adnum'].value_counts()))\n",
    "#df[['mis']]=StandardScaler().fit_transform(df[['mis']])\n",
    "\n",
    "def x_modelling(df):\n",
    "    #df=df[['pat_weight_act','Age','Adnum','mis']]\n",
    "    df=df.drop(['Extubation_date','pat_datetime'],axis=1)\n",
    "    df=df.groupby(['Adnum'],sort=False).agg(['mean'])\n",
    "    df.columns = df.columns.droplevel(1)\n",
    "    df=df.reset_index().drop_duplicates().set_index('Adnum')\n",
    "    df=df.fillna(method='ffill').fillna(method='bfill')\n",
    "    \n",
    "    return df\n",
    "df_temp=x_modelling(df)\n",
    "print(df_temp.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 327 entries, 104 to 246\n",
      "Data columns (total 14 columns):\n",
      " #   Column                                   Non-Null Count  Dtype  \n",
      "---  ------                                   --------------  -----  \n",
      " 0   Weight (kgs)                             327 non-null    float32\n",
      " 1   End tidal CO2 (mmHg)                     327 non-null    float32\n",
      " 2   Heart rate                               327 non-null    float32\n",
      " 3   Invasive blood pressure (mmHg)           327 non-null    float32\n",
      " 4   Respiratory rate                         327 non-null    float32\n",
      " 5   Saturation (%)                           327 non-null    float32\n",
      " 6   Inspiratory oxygen (%)                   327 non-null    float32\n",
      " 7   Ventilator PEEP (mmHg)                   327 non-null    float32\n",
      " 8   Ventilator peak pressure (mmHg)          327 non-null    float32\n",
      " 9   Ventilator respiratory rate              327 non-null    float32\n",
      " 10  Ventilator expiratory tidal volume (mL)  327 non-null    float32\n",
      " 11  Age (years)                              327 non-null    float32\n",
      " 12  Reintub                                  327 non-null    int64  \n",
      " 13  Time gap (min)                           327 non-null    float64\n",
      "dtypes: float32(12), float64(1), int64(1)\n",
      "memory usage: 23.0 KB\n",
      "None\n",
      "+----------------------------------------------------+----+-----------+--------------+--------------+--------------+-----------+\n",
      "|                                                    |    | Missing   | Overall      | 0            | 1            | P-Value   |\n",
      "+====================================================+====+===========+==============+==============+==============+===========+\n",
      "| n                                                  |    |           | 327          | 291          | 36           |           |\n",
      "+----------------------------------------------------+----+-----------+--------------+--------------+--------------+-----------+\n",
      "| Age (years), mean (SD)                             |    | 0         | 0.3 (0.5)    | 0.3 (0.5)    | 0.4 (0.5)    | 0.407     |\n",
      "+----------------------------------------------------+----+-----------+--------------+--------------+--------------+-----------+\n",
      "| Weight (kgs), mean (SD)                            |    | 0         | 5.7 (2.5)    | 5.6 (2.4)    | 6.3 (2.7)    | 0.169     |\n",
      "+----------------------------------------------------+----+-----------+--------------+--------------+--------------+-----------+\n",
      "| Respiratory rate, mean (SD)                        |    | 0         | 39.1 (6.9)   | 39.1 (7.0)   | 39.2 (6.6)   | 0.990     |\n",
      "+----------------------------------------------------+----+-----------+--------------+--------------+--------------+-----------+\n",
      "| Heart rate, mean (SD)                              |    | 0         | 140.5 (16.9) | 141.2 (16.7) | 135.1 (17.2) | 0.049     |\n",
      "+----------------------------------------------------+----+-----------+--------------+--------------+--------------+-----------+\n",
      "| Saturation (%), mean (SD)                          |    | 0         | 96.8 (3.4)   | 96.7 (3.5)   | 96.8 (1.7)   | 0.940     |\n",
      "+----------------------------------------------------+----+-----------+--------------+--------------+--------------+-----------+\n",
      "| End tidal CO2 (mmHg), mean (SD)                    |    | 0         | 40.9 (6.1)   | 41.0 (6.1)   | 39.9 (6.1)   | 0.308     |\n",
      "+----------------------------------------------------+----+-----------+--------------+--------------+--------------+-----------+\n",
      "| Inspiratory oxygen (%), mean (SD)                  |    | 0         | 35.4 (10.2)  | 35.1 (10.3)  | 37.6 (8.9)   | 0.124     |\n",
      "+----------------------------------------------------+----+-----------+--------------+--------------+--------------+-----------+\n",
      "| Ventilator peak pressure (mmHg), mean (SD)         |    | 0         | 16.2 (5.3)   | 15.9 (5.2)   | 18.8 (5.1)   | 0.002     |\n",
      "+----------------------------------------------------+----+-----------+--------------+--------------+--------------+-----------+\n",
      "| Ventilator PEEP (mmHg), mean (SD)                  |    | 0         | 5.6 (1.5)    | 5.6 (1.4)    | 5.8 (2.0)    | 0.579     |\n",
      "+----------------------------------------------------+----+-----------+--------------+--------------+--------------+-----------+\n",
      "| Invasive blood pressure (mmHg), mean (SD)          |    | 0         | 66.8 (9.6)   | 66.5 (9.0)   | 69.0 (13.3)  | 0.294     |\n",
      "+----------------------------------------------------+----+-----------+--------------+--------------+--------------+-----------+\n",
      "| Ventilator respiratory rate, mean (SD)             |    | 0         | 38.9 (12.7)  | 39.0 (12.8)  | 37.7 (12.0)  | 0.543     |\n",
      "+----------------------------------------------------+----+-----------+--------------+--------------+--------------+-----------+\n",
      "| Ventilator expiratory tidal volume (mL), mean (SD) |    | 0         | 34.1 (24.8)  | 33.6 (24.9)  | 38.2 (23.7)  | 0.282     |\n",
      "+----------------------------------------------------+----+-----------+--------------+--------------+--------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_temp=df_temp.rename(columns=rename_dict)\n",
    "print(df_temp.info())\n",
    "columns= list(rename_dict.values())\n",
    "\n",
    "mytable=TableOne(df_temp,columns=columns,groupby='Reintub',pval=True)\n",
    "print(mytable.tabulate(tablefmt=\"grid\"))\n",
    "mytable.to_excel(os.path.join('./Results','Table_1_pat.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "df=df.reset_index(drop=False)\n",
    "df.info()\n",
    "def index_1hr(group):\n",
    "    group['mis']=(group['pat_datetime'].max()-group['pat_datetime'].min()).total_seconds()/60\n",
    "    return group\n",
    "#grouped = pd.Grouper(key='pat_datetime', freq='60min',label='left',convention='start')\n",
    "#df['idx_1hr']=df.groupby(['Adnum','pat_hosp_id','AdmissionDate','DischargeDate'],sort=False,as_index=False).ngroup().add(1)\n",
    "df=df.groupby('Adnum',sort=False,as_index=False).apply(index_1hr)\n",
    "print((df['Adnum'].value_counts()))\n",
    "df[['mis']]=StandardScaler().fit_transform(df[['mis']])\n",
    "df=df.set_index(['pat_hosp_id','AdmissionDate','DischargeDate'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pat=pd.read_excel(r'Results\\admissiondate_v2.xlsx', parse_dates=[\n",
    "                            'AdmissionDate', 'DischargeDate'])\n",
    "group=pat.groupby('pat_hosp_id',sort=False).max().reset_index()\n",
    "group.drop_duplicates('pat_hosp_id',inplace=True)\n",
    "df_train,df_val,df_test=pp.split_stratified_into_train_val_test(group, stratify_colname='Reintub',\n",
    "                                         frac_train=0.60, frac_val=0.1, frac_test=0.3,\n",
    "                                         random_state=1)\n",
    "print(df_train.info())\n",
    "\n",
    "train_pat=df_train['pat_hosp_id'].unique()\n",
    "test_pat=df_test['pat_hosp_id'].unique()\n",
    "val_pat=df_val['pat_hosp_id'].unique()\n",
    "\n",
    "df_train = df[df.index.get_level_values('pat_hosp_id').isin(train_pat)]\n",
    "df_val = df[df.index.get_level_values('pat_hosp_id').isin(val_pat)]\n",
    "df_test = df[df.index.get_level_values('pat_hosp_id').isin(test_pat)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def y_modelling(df):\n",
    "    y=df[['Reintub','Adnum']]\n",
    "    y=y.groupby(['Adnum'],sort=False).agg(['max'])\n",
    "    y.columns = [\"_\".join(a) for a in y.columns.to_flat_index()]\n",
    "    y=y.reset_index().drop_duplicates().set_index('Adnum')\n",
    "    y=y[~y.index.duplicated(keep='last')]\n",
    "    y=y.fillna(method='ffill').fillna(method='bfill')\n",
    "    return y\n",
    "Y_TRAIN=y_modelling(df_train)\n",
    "Y_TEST=y_modelling(df_test)\n",
    "Y_VAL=y_modelling(df_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_TRAIN.value_counts())\n",
    "print(Y_VAL.value_counts())\n",
    "print(Y_TEST.value_counts())\n",
    "Y_TRAIN=Y_TRAIN['Reintub_max'].to_numpy()\n",
    "Y_TEST=Y_TEST['Reintub_max'].to_numpy()\n",
    "Y_VAL=Y_VAL['Reintub_max'].to_numpy()\n",
    "Y_TRAIN=np.append(Y_TRAIN,Y_VAL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_modelling(df):\n",
    "    #df=df[['pat_weight_act','Age','Adnum','mis']]\n",
    "    df=df.drop(['Extubation_date','level_0','pat_datetime', 'Reintub'],axis=1)\n",
    "    df=df.groupby(['Adnum'],sort=False).agg(['mean'])\n",
    "    df.columns = [\"_\".join(a) for a in df.columns.to_flat_index()]\n",
    "    df=df.reset_index().drop_duplicates().set_index('Adnum')\n",
    "    df=df.fillna(method='ffill').fillna(method='bfill')\n",
    "    return df\n",
    "X_TRAIN=x_modelling(df_train)\n",
    "X_TEST=x_modelling(df_test)\n",
    "X_VAL=x_modelling(df_val)\n",
    "print(X_TRAIN.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TRAIN=X_TRAIN.append(X_VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(os.path.join(output_folder, 'x_train.txt'), 'wb')\n",
    "pickle.dump(X_TRAIN, f)\n",
    "f.close()\n",
    "\n",
    "f = open(os.path.join(output_folder, 'x_test.txt'), 'wb')\n",
    "pickle.dump(X_TEST, f)\n",
    "f.close()\n",
    "\n",
    "f = open(os.path.join(output_folder, 'y_train.txt'), 'wb')\n",
    "pickle.dump(Y_TRAIN, f)\n",
    "f.close()\n",
    "\n",
    "f = open(os.path.join(output_folder, 'y_test.txt'), 'wb')\n",
    "pickle.dump(Y_TEST, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 50, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [1,2,3,4, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 30, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_TRAIN, Y_TRAIN)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix,average_precision_score,f1_score,roc_curve,roc_auc_score,plot_confusion_matrix\n",
    "\n",
    "base_model = RandomForestClassifier(n_estimators = 10, random_state = 42,max_depth=10)\n",
    "base_model.fit(X_TRAIN, Y_TRAIN)\n",
    "base_accuracy = evaluate(base_model, X_TEST, Y_TEST,'base RF',output_folder)\n",
    "\n",
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy = evaluate(best_random, X_TEST,Y_TEST,'Best random RF',output_folder)\n",
    "\n",
    "if base_accuracy > random_accuracy:\n",
    "    best_random = base_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix,average_precision_score,f1_score,roc_curve,roc_auc_score,plot_confusion_matrix\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "from all_own_funct import roc_auc_ci\n",
    "try:\n",
    "    pdf = PdfPages(os.path.join(output_folder,f\"Figures_all_t.pdf\"))\n",
    "except PermissionError:\n",
    "    os.remove(os.path.join(output_folder,f\"Figures_all.pdf\"))\n",
    "    os.remove(os.path.join(output_folder,f\"Result_scores_all.txt\"))\n",
    "clf = best_random \n",
    "\n",
    "y_pred_clas=clf.predict(X_TEST)\n",
    "# Predict the probabilities, function depends on used classifier\n",
    "\n",
    "try:\n",
    "    y_pred_prob=clf.predict_proba(X_TEST)\n",
    "    y_pred_prob=y_pred_prob[:,1]\n",
    "except:\n",
    "    try:\n",
    "        y_pred_prob=clf.decision_function(X_TEST)\n",
    "    except:\n",
    "        y_pred_prob=y_pred_clas\n",
    "\n",
    "report=classification_report(Y_TEST,y_pred_clas,target_names=['No Reintubation','Reintubation'])\n",
    "score=clf.score(X_TEST,Y_TEST)\n",
    "average_precision = average_precision_score(Y_TEST, y_pred_prob)\n",
    "f1_s=f1_score(Y_TEST, y_pred_clas)\n",
    "\n",
    "# write scoring metrics to file\n",
    "with open(os.path.join(output_folder,f\"Result_scores_all.txt\"),'a') as file:\n",
    "    file.write(f\"Results for RF on training set\\n\\n\")\n",
    "    file.write(f\"Classification report \\n {report} \\n\")\n",
    "    file.write(f\"Hold_out_scores {score} \\n\")\n",
    "    file.write(f\"Average precision score {average_precision} \\n\")\n",
    "    file.write(f\"F1 score {f1_s} \\n\\n\\n\")\n",
    "\n",
    "plot_confusion_matrix(clf,X_TEST,Y_TEST)\n",
    "plt.title(f\"Confusion matrix of random forrest\")\n",
    "fig=plt.gcf()\n",
    "pdf.savefig(fig)\n",
    "plt.close(fig)\n",
    "\n",
    "fpr, tpr, _ = roc_curve(Y_TEST,  y_pred_prob)\n",
    "auc = roc_auc_score(Y_TEST, y_pred_prob)\n",
    "\n",
    "n_bootstraps = 2000\n",
    "rng_seed = 42  # control reproducibility\n",
    "bootstrapped_scores = []\n",
    "\n",
    "rng = np.random.RandomState(rng_seed)\n",
    "for i in range(n_bootstraps):\n",
    "    # bootstrap by sampling with replacement on the prediction indices\n",
    "    indices = rng.randint(0, len(y_pred_prob), len(y_pred_prob))\n",
    "    if len(np.unique(Y_TEST[indices])) < 2:\n",
    "        # We need at least one positive and one negative sample for ROC AUC\n",
    "        # to be defined: reject the sample\n",
    "        continue\n",
    "\n",
    "    score = roc_auc_score(Y_TEST[indices], y_pred_prob[indices])\n",
    "    bootstrapped_scores.append(score)\n",
    "    #print(\"Bootstrap #{} ROC area: {:0.3f}\".format(i + 1, score))\n",
    "\n",
    "sorted_scores = np.array(bootstrapped_scores)\n",
    "sorted_scores.sort()\n",
    "\n",
    "# Computing the lower and upper bound of the 90% confidence interval\n",
    "# You can change the bounds percentiles to 0.025 and 0.975 to get\n",
    "# a 95% confidence interval instead.\n",
    "confidence_lower = sorted_scores[int(0.05 * len(sorted_scores))]\n",
    "confidence_upper = sorted_scores[int(0.95 * len(sorted_scores))]\n",
    "print(\"Confidence interval for the score: [{:0.3f} - {:0.3}]\".format(\n",
    "    confidence_lower, confidence_upper))\n",
    "a=roc_auc_ci(Y_TEST,y_pred_prob)\n",
    "print(a)\n",
    "\n",
    "\n",
    "plt.plot(fpr,tpr,label=f\"auc={auc}\",linewidth=1.5,markersize=1)\n",
    "\n",
    "plt.legend(loc=4,fontsize='xx-small')\n",
    "plt.title(f'ROC of Random Forrest hour data')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([0,1])\n",
    "axes.set_ylim([0,1])\n",
    "fig=plt.gcf()\n",
    "pdf.savefig(fig)\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "# Number of features to consider at every split\n",
    "solver =['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "# Maximum number of levels in tree\n",
    "class_weight=[{0:0.1,1:0.9},'balanced',None]\n",
    "# Minimum number of samples required to split a node\n",
    "penalty=['l1', 'l2', 'elasticnet', None]\n",
    "# Minimum number of samples required at each leaf node\n",
    "C=np.logspace(-3,3,7)\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'solver':solver,\n",
    "                'class_weight':class_weight,\n",
    "                'penalty':penalty,\n",
    "                'C':C,\n",
    "                'penalty':penalty}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create the base model to tune\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "lr_random = RandomizedSearchCV(estimator = lr , param_distributions = random_grid, n_iter = 20, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "lr_random.fit(X_TRAIN, Y_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_lr = LogisticRegression(max_iter=1000)\n",
    "base_model_lr.fit(X_TRAIN, Y_TRAIN)\n",
    "base_accuracy_lr = evaluate(base_model, X_TEST, Y_TEST,'base LR',output_folder)\n",
    "\n",
    "best_random_lr = lr_random.best_estimator_\n",
    "random_accuracy_lr = evaluate(best_random, X_TEST,Y_TEST,'Best Random LR',output_folder)\n",
    "if base_accuracy_lr > random_accuracy_lr:\n",
    "    best_random_lr = base_model_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = best_random_lr\n",
    "\n",
    "y_pred_clas=clf.predict(X_TEST)\n",
    "# Predict the probabilities, function depends on used classifier\n",
    "\n",
    "try:\n",
    "    y_pred_prob=clf.predict_proba(X_TEST)\n",
    "    y_pred_prob=y_pred_prob[:,1]\n",
    "except:\n",
    "    try:\n",
    "        y_pred_prob=clf.decision_function(X_TEST)\n",
    "    except:\n",
    "        y_pred_prob=y_pred_clas\n",
    "\n",
    "report=classification_report(Y_TEST,y_pred_clas,target_names=['No Reintubation','Reintubation'])\n",
    "score=clf.score(X_TEST,Y_TEST)\n",
    "average_precision = average_precision_score(Y_TEST, y_pred_prob)\n",
    "f1_s=f1_score(Y_TEST, y_pred_clas)\n",
    "\n",
    "with open(os.path.join(output_folder,f\"Result_scores_all.txt\"),'a') as file:\n",
    "    file.write(f\"Results for LR on training\\n\\n\")\n",
    "    file.write(f\"Classification report \\n {report} \\n\")\n",
    "    file.write(f\"Hold_out_scores {score} \\n\")\n",
    "    file.write(f\"Average precision score {average_precision} \\n\")\n",
    "    file.write(f\"F1 score {f1_s} \\n\\n\\n\")\n",
    "\n",
    "plot_confusion_matrix(clf,X_TEST,Y_TEST)\n",
    "plt.title(f\"Confusion matrix of logistic regression\")\n",
    "fig=plt.gcf()\n",
    "pdf.savefig(fig)\n",
    "plt.close(fig)\n",
    "\n",
    "fpr, tpr, _ = roc_curve(Y_TEST,  y_pred_prob)\n",
    "auc = roc_auc_score(Y_TEST, y_pred_prob)\n",
    "print(auc)\n",
    "\n",
    "n_bootstraps = 2000\n",
    "rng_seed = 42  # control reproducibility\n",
    "bootstrapped_scores = []\n",
    "\n",
    "rng = np.random.RandomState(rng_seed)\n",
    "for i in range(n_bootstraps):\n",
    "    # bootstrap by sampling with replacement on the prediction indices\n",
    "    indices = rng.randint(0, len(y_pred_prob), len(y_pred_prob))\n",
    "    if len(np.unique(Y_TEST[indices])) < 2:\n",
    "        # We need at least one positive and one negative sample for ROC AUC\n",
    "        # to be defined: reject the sample\n",
    "        continue\n",
    "\n",
    "    score = roc_auc_score(Y_TEST[indices], y_pred_prob[indices])\n",
    "    bootstrapped_scores.append(score)\n",
    "    #print(\"Bootstrap #{} ROC area: {:0.3f}\".format(i + 1, score))\n",
    "\n",
    "sorted_scores = np.array(bootstrapped_scores)\n",
    "sorted_scores.sort()\n",
    "\n",
    "# Computing the lower and upper bound of the 90% confidence interval\n",
    "# You can change the bounds percentiles to 0.025 and 0.975 to get\n",
    "# a 95% confidence interval instead.\n",
    "confidence_lower = sorted_scores[int(0.05 * len(sorted_scores))]\n",
    "confidence_upper = sorted_scores[int(0.95 * len(sorted_scores))]\n",
    "print(\"Confidence interval for the score: [{:0.3f} - {:0.3}]\".format(\n",
    "    confidence_lower, confidence_upper))\n",
    "\n",
    "a=roc_auc_ci(Y_TEST,y_pred_prob)\n",
    "print(a)\n",
    "\n",
    "plt.plot(fpr,tpr,label=f\"auc={auc}\",linewidth=1.5,markersize=1)\n",
    "\n",
    "\n",
    "plt.legend(loc=4,fontsize='xx-small')\n",
    "plt.title(f'ROC of Logistic Regression data')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([0,1])\n",
    "axes.set_ylim([0,1])\n",
    "fig=plt.gcf()\n",
    "pdf.savefig(fig)\n",
    "plt.close(fig)\n",
    "pdf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open(os.path.join(output_folder,'ran_for.sav'), 'wb')\n",
    "pickle.dump(best_random, f)\n",
    "f.close()\n",
    "\n",
    "f = open(os.path.join(output_folder,'log_reg.sav'), 'wb')\n",
    "pickle.dump(best_random_lr, f)\n",
    "f.close()"
   ]
  }
 ]
}